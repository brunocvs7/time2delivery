{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, We are going to explore the dataset to try to get the data prepared for exploratory data analysis and feature engineering. We'll go through all of the steps listed bellow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Column Type verification\n",
    "- Casting\n",
    "- Inconsistencies\n",
    "- Missing Values\n",
    "- Analysis of Constant and Quasi-constant columns\n",
    "- Rare Categories\n",
    "- Duplicate Rows\n",
    "- Duplicate Columns\n",
    "- Data Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libs\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from utils.data.cleaning import check_dtypes, cast_columns, check_missing, check_constant_columns, check_rare_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import importlib\n",
    "#importlib.reload(utils.data.cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enviroment\n",
    "load_dotenv(find_dotenv())\n",
    "# Path variables\n",
    "DATA_INPUT_PATH = os.getenv('DATA_RAW_PATH')\n",
    "DATA_OUTPUT_PATH = os.getenv('DATA_PROCESSED_PATH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "df_orders = pd.read_csv(os.path.join(DATA_INPUT_PATH, 'all_orders.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>lat_os</th>\n",
       "      <th>lng_os</th>\n",
       "      <th>promised_time</th>\n",
       "      <th>on_demand</th>\n",
       "      <th>shopper_id</th>\n",
       "      <th>store_branch_id</th>\n",
       "      <th>total_minutes</th>\n",
       "      <th>seniority</th>\n",
       "      <th>found_rate</th>\n",
       "      <th>picking_speed</th>\n",
       "      <th>accepted_rate</th>\n",
       "      <th>rating</th>\n",
       "      <th>store_id</th>\n",
       "      <th>lat_strb</th>\n",
       "      <th>lng_strb</th>\n",
       "      <th>sum_kgs</th>\n",
       "      <th>sum_unities</th>\n",
       "      <th>n_distinct_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e750294655c2c7c34d83cc3181c09de4</td>\n",
       "      <td>-33.501675</td>\n",
       "      <td>-70.579369</td>\n",
       "      <td>2019-10-18 20:48:00+00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>e63bc83a1a952fa2b3cc9d558fb943cf</td>\n",
       "      <td>65ded5353c5ee48d0b7d48c591b8f430</td>\n",
       "      <td>67.684264</td>\n",
       "      <td>6c90661e6d2c7579f5ce337c3391dbb9</td>\n",
       "      <td>0.9024</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.92</td>\n",
       "      <td>4.76</td>\n",
       "      <td>c4ca4238a0b923820dcc509a6f75849b</td>\n",
       "      <td>-33.485280</td>\n",
       "      <td>-70.579250</td>\n",
       "      <td>2.756</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6581174846221cb6c467348e87f57641</td>\n",
       "      <td>-33.440584</td>\n",
       "      <td>-70.556283</td>\n",
       "      <td>2019-10-19 01:00:00+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>195f9e9d84a4ba9033c4b6a756334d8b</td>\n",
       "      <td>45fbc6d3e05ebd93369ce542e8f2322d</td>\n",
       "      <td>57.060632</td>\n",
       "      <td>41dc7c9e385c4d2b6c1f7836973951bf</td>\n",
       "      <td>0.7610</td>\n",
       "      <td>2.54</td>\n",
       "      <td>0.92</td>\n",
       "      <td>4.96</td>\n",
       "      <td>c4ca4238a0b923820dcc509a6f75849b</td>\n",
       "      <td>-33.441246</td>\n",
       "      <td>-70.535450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3a226ea48debc0a7ae9950d5540f2f34</td>\n",
       "      <td>-32.987022</td>\n",
       "      <td>-71.544842</td>\n",
       "      <td>2019-10-19 14:54:00+00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>a5b9ddc0d82e61582fca19ad43dbaacb</td>\n",
       "      <td>07563a3fe3bbe7e3ba84431ad9d055af</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50e13ee63f086c2fe84229348bc91b5b</td>\n",
       "      <td>0.8313</td>\n",
       "      <td>2.57</td>\n",
       "      <td>0.76</td>\n",
       "      <td>4.92</td>\n",
       "      <td>c4ca4238a0b923820dcc509a6f75849b</td>\n",
       "      <td>-33.008213</td>\n",
       "      <td>-71.545615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7d2ed03fe4966083e74b12694b1669d8</td>\n",
       "      <td>-33.328075</td>\n",
       "      <td>-70.512659</td>\n",
       "      <td>2019-10-18 21:47:00+00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>d0b3f6bf7e249e5ebb8d3129341773a2</td>\n",
       "      <td>f1748d6b0fd9d439f71450117eba2725</td>\n",
       "      <td>52.067742</td>\n",
       "      <td>41dc7c9e385c4d2b6c1f7836973951bf</td>\n",
       "      <td>0.8776</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.96</td>\n",
       "      <td>4.76</td>\n",
       "      <td>f718499c1c8cef6730f9fd03c8125cab</td>\n",
       "      <td>-33.355258</td>\n",
       "      <td>-70.537787</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b4b2682d77118155fe4716300ccf7f39</td>\n",
       "      <td>-33.403239</td>\n",
       "      <td>-70.564020</td>\n",
       "      <td>2019-10-19 20:00:00+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>5c5199ce02f7b77caa9c2590a39ad27d</td>\n",
       "      <td>1f0e3dad99908345f7439f8ffabdffc4</td>\n",
       "      <td>140.724822</td>\n",
       "      <td>50e13ee63f086c2fe84229348bc91b5b</td>\n",
       "      <td>0.7838</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.96</td>\n",
       "      <td>4.96</td>\n",
       "      <td>c4ca4238a0b923820dcc509a6f75849b</td>\n",
       "      <td>-33.386547</td>\n",
       "      <td>-70.568075</td>\n",
       "      <td>6.721</td>\n",
       "      <td>91.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id     lat_os     lng_os  \\\n",
       "0  e750294655c2c7c34d83cc3181c09de4 -33.501675 -70.579369   \n",
       "1  6581174846221cb6c467348e87f57641 -33.440584 -70.556283   \n",
       "2  3a226ea48debc0a7ae9950d5540f2f34 -32.987022 -71.544842   \n",
       "3  7d2ed03fe4966083e74b12694b1669d8 -33.328075 -70.512659   \n",
       "4  b4b2682d77118155fe4716300ccf7f39 -33.403239 -70.564020   \n",
       "\n",
       "               promised_time  on_demand                        shopper_id  \\\n",
       "0  2019-10-18 20:48:00+00:00       True  e63bc83a1a952fa2b3cc9d558fb943cf   \n",
       "1  2019-10-19 01:00:00+00:00      False  195f9e9d84a4ba9033c4b6a756334d8b   \n",
       "2  2019-10-19 14:54:00+00:00       True  a5b9ddc0d82e61582fca19ad43dbaacb   \n",
       "3  2019-10-18 21:47:00+00:00       True  d0b3f6bf7e249e5ebb8d3129341773a2   \n",
       "4  2019-10-19 20:00:00+00:00      False  5c5199ce02f7b77caa9c2590a39ad27d   \n",
       "\n",
       "                    store_branch_id  total_minutes  \\\n",
       "0  65ded5353c5ee48d0b7d48c591b8f430      67.684264   \n",
       "1  45fbc6d3e05ebd93369ce542e8f2322d      57.060632   \n",
       "2  07563a3fe3bbe7e3ba84431ad9d055af            NaN   \n",
       "3  f1748d6b0fd9d439f71450117eba2725      52.067742   \n",
       "4  1f0e3dad99908345f7439f8ffabdffc4     140.724822   \n",
       "\n",
       "                          seniority  found_rate  picking_speed  accepted_rate  \\\n",
       "0  6c90661e6d2c7579f5ce337c3391dbb9      0.9024           1.30           0.92   \n",
       "1  41dc7c9e385c4d2b6c1f7836973951bf      0.7610           2.54           0.92   \n",
       "2  50e13ee63f086c2fe84229348bc91b5b      0.8313           2.57           0.76   \n",
       "3  41dc7c9e385c4d2b6c1f7836973951bf      0.8776           2.80           0.96   \n",
       "4  50e13ee63f086c2fe84229348bc91b5b      0.7838           2.40           0.96   \n",
       "\n",
       "   rating                          store_id   lat_strb   lng_strb  sum_kgs  \\\n",
       "0    4.76  c4ca4238a0b923820dcc509a6f75849b -33.485280 -70.579250    2.756   \n",
       "1    4.96  c4ca4238a0b923820dcc509a6f75849b -33.441246 -70.535450      NaN   \n",
       "2    4.92  c4ca4238a0b923820dcc509a6f75849b -33.008213 -71.545615      NaN   \n",
       "3    4.76  f718499c1c8cef6730f9fd03c8125cab -33.355258 -70.537787      NaN   \n",
       "4    4.96  c4ca4238a0b923820dcc509a6f75849b -33.386547 -70.568075    6.721   \n",
       "\n",
       "   sum_unities  n_distinct_items  \n",
       "0         16.0              19.0  \n",
       "1         11.0               5.0  \n",
       "2         18.0               5.0  \n",
       "3          1.0               1.0  \n",
       "4         91.0              51.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_types = check_dtypes(df_orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'object': ['order_id',\n",
       "  'promised_time',\n",
       "  'shopper_id',\n",
       "  'store_branch_id',\n",
       "  'seniority',\n",
       "  'store_id'],\n",
       " 'float64': ['lat_os',\n",
       "  'lng_os',\n",
       "  'total_minutes',\n",
       "  'found_rate',\n",
       "  'picking_speed',\n",
       "  'accepted_rate',\n",
       "  'rating',\n",
       "  'lat_strb',\n",
       "  'lng_strb',\n",
       "  'sum_kgs',\n",
       "  'sum_unities',\n",
       "  'n_distinct_items'],\n",
       " 'bool': ['on_demand']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically there are three types of columns: `float64`, `bool` and `object`. The column `promised_time`, though, is representing time, maybe We should cast this one to datetime format. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2) Casting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As We don't know at first which are the useful columns, let's just cast them to the right format, and once We assess its predictive power and decide to bring them in traning phase, We'll create a python function or transformer to cover this step in the pipeline of transformation and cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# promised_time to datetime and ond_demand to object\n",
    "df_orders = cast_columns(df=df_orders, \n",
    "                         casting={'promised_time':'datetime64[ns]',\n",
    "                                  'on_demand':'object'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                    object\n",
       "lat_os                     float64\n",
       "lng_os                     float64\n",
       "promised_time       datetime64[ns]\n",
       "on_demand                   object\n",
       "shopper_id                  object\n",
       "store_branch_id             object\n",
       "total_minutes              float64\n",
       "seniority                   object\n",
       "found_rate                 float64\n",
       "picking_speed              float64\n",
       "accepted_rate              float64\n",
       "rating                     float64\n",
       "store_id                    object\n",
       "lat_strb                   float64\n",
       "lng_strb                   float64\n",
       "sum_kgs                    float64\n",
       "sum_unities                float64\n",
       "n_distinct_items           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orders.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3) Inconsistencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for inconsistencies is a mandatory step in our analysis. Here, We'll check for the boundaries around the numerical features to see if some weird pattern appears (negative time, for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat_os</th>\n",
       "      <th>lng_os</th>\n",
       "      <th>total_minutes</th>\n",
       "      <th>found_rate</th>\n",
       "      <th>picking_speed</th>\n",
       "      <th>accepted_rate</th>\n",
       "      <th>rating</th>\n",
       "      <th>lat_strb</th>\n",
       "      <th>lng_strb</th>\n",
       "      <th>sum_kgs</th>\n",
       "      <th>sum_unities</th>\n",
       "      <th>n_distinct_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>9800.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>9954.000000</td>\n",
       "      <td>9837.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>6332.000000</td>\n",
       "      <td>9900.00000</td>\n",
       "      <td>9978.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-33.427090</td>\n",
       "      <td>-70.668017</td>\n",
       "      <td>81.106130</td>\n",
       "      <td>0.863309</td>\n",
       "      <td>1.686800</td>\n",
       "      <td>0.916928</td>\n",
       "      <td>4.849213</td>\n",
       "      <td>-33.431499</td>\n",
       "      <td>-70.661844</td>\n",
       "      <td>2.738629</td>\n",
       "      <td>34.82303</td>\n",
       "      <td>19.893766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.558675</td>\n",
       "      <td>0.400249</td>\n",
       "      <td>34.720837</td>\n",
       "      <td>0.029801</td>\n",
       "      <td>0.626378</td>\n",
       "      <td>0.097246</td>\n",
       "      <td>0.128929</td>\n",
       "      <td>0.555641</td>\n",
       "      <td>0.400569</td>\n",
       "      <td>2.736629</td>\n",
       "      <td>33.15926</td>\n",
       "      <td>16.434651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-36.942135</td>\n",
       "      <td>-73.144280</td>\n",
       "      <td>11.969489</td>\n",
       "      <td>0.737300</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>-36.904347</td>\n",
       "      <td>-73.096660</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-33.426861</td>\n",
       "      <td>-70.605795</td>\n",
       "      <td>55.225480</td>\n",
       "      <td>0.846300</td>\n",
       "      <td>1.260000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>-33.440823</td>\n",
       "      <td>-70.599000</td>\n",
       "      <td>0.948000</td>\n",
       "      <td>11.00000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-33.398110</td>\n",
       "      <td>-70.574591</td>\n",
       "      <td>74.731672</td>\n",
       "      <td>0.866000</td>\n",
       "      <td>1.510000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>4.880000</td>\n",
       "      <td>-33.386547</td>\n",
       "      <td>-70.568075</td>\n",
       "      <td>1.926000</td>\n",
       "      <td>26.00000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-33.353783</td>\n",
       "      <td>-70.540307</td>\n",
       "      <td>100.273498</td>\n",
       "      <td>0.883600</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.960000</td>\n",
       "      <td>-33.370765</td>\n",
       "      <td>-70.521372</td>\n",
       "      <td>3.602000</td>\n",
       "      <td>49.00000</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-29.833517</td>\n",
       "      <td>-70.453728</td>\n",
       "      <td>304.190303</td>\n",
       "      <td>0.971000</td>\n",
       "      <td>7.040000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-29.901425</td>\n",
       "      <td>-70.492256</td>\n",
       "      <td>32.492000</td>\n",
       "      <td>335.00000</td>\n",
       "      <td>145.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             lat_os        lng_os  total_minutes   found_rate  picking_speed  \\\n",
       "count  10000.000000  10000.000000    8000.000000  9800.000000   10000.000000   \n",
       "mean     -33.427090    -70.668017      81.106130     0.863309       1.686800   \n",
       "std        0.558675      0.400249      34.720837     0.029801       0.626378   \n",
       "min      -36.942135    -73.144280      11.969489     0.737300       0.650000   \n",
       "25%      -33.426861    -70.605795      55.225480     0.846300       1.260000   \n",
       "50%      -33.398110    -70.574591      74.731672     0.866000       1.510000   \n",
       "75%      -33.353783    -70.540307     100.273498     0.883600       2.000000   \n",
       "max      -29.833517    -70.453728     304.190303     0.971000       7.040000   \n",
       "\n",
       "       accepted_rate       rating      lat_strb      lng_strb      sum_kgs  \\\n",
       "count    9954.000000  9837.000000  10000.000000  10000.000000  6332.000000   \n",
       "mean        0.916928     4.849213    -33.431499    -70.661844     2.738629   \n",
       "std         0.097246     0.128929      0.555641      0.400569     2.736629   \n",
       "min         0.240000     3.880000    -36.904347    -73.096660     0.055000   \n",
       "25%         0.880000     4.800000    -33.440823    -70.599000     0.948000   \n",
       "50%         0.960000     4.880000    -33.386547    -70.568075     1.926000   \n",
       "75%         1.000000     4.960000    -33.370765    -70.521372     3.602000   \n",
       "max         1.000000     5.000000    -29.901425    -70.492256    32.492000   \n",
       "\n",
       "       sum_unities  n_distinct_items  \n",
       "count   9900.00000       9978.000000  \n",
       "mean      34.82303         19.893766  \n",
       "std       33.15926         16.434651  \n",
       "min        1.00000          1.000000  \n",
       "25%       11.00000          8.000000  \n",
       "50%       26.00000         16.000000  \n",
       "75%       49.00000         28.000000  \n",
       "max      335.00000        145.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orders.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lat and Long information  are semingly in valid range. found_rate and accepted_rate are between 0 and 1, total_minutes is always greater than 0. Everything is ok, semingly. Just one thing to point out: If lat/long information appears at highly important for the model, We'll have to create some validation step to assure It makes sense (We don't want to pass ocean coordinates to the model, right?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4) Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_missing = check_missing(df_orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sum_kgs             0.3668\n",
       "total_minutes       0.2000\n",
       "found_rate          0.0200\n",
       "rating              0.0163\n",
       "sum_unities         0.0100\n",
       "accepted_rate       0.0046\n",
       "n_distinct_items    0.0022\n",
       "store_branch_id     0.0000\n",
       "seniority           0.0000\n",
       "lat_os              0.0000\n",
       "picking_speed       0.0000\n",
       "shopper_id          0.0000\n",
       "on_demand           0.0000\n",
       "store_id            0.0000\n",
       "lat_strb            0.0000\n",
       "lng_strb            0.0000\n",
       "promised_time       0.0000\n",
       "lng_os              0.0000\n",
       "order_id            0.0000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `sum_kgs`: It represents the total quantity (in kg) of the order. Missing means 0 kg, so We'll fill missing values with 0 for this column\n",
    "- `sum_unities`: It is the same situation as sum_kgs. Let's replace missing values with 0.\n",
    "- `n_distinct_items`: It's weird that we have found missing values in this column, but It is a very low frequency event. So, We can use median safely.\n",
    "- `rating`, `found_rate` and `accepted_rate`: All of these columns can be filled with median, because the rate of missing values is really low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `total_minutes`: This column is our target variable. As the README.md attached in the repo suggests, Let's consider all rows with missing values at this column as our submision set. So, let's set these rows aside from development and only use them in predict step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5) Constant and Quasi-constant Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As machine learning models benefit from variability in the data, Let's remove constant columns and quasi-constant columns (most frequent value higher than a threshold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Constant Column Found\n",
      "No Quasi-Constant Column Found\n"
     ]
    }
   ],
   "source": [
    "constant_columns, quasi_constant_columns = check_constant_columns(df_orders, threshold=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As We have not found any constant or quasi-constant, We'll not drop any column by this criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6) Rare Categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rare categorical levels are a problem, because not always We have enough data of them to provide for the machine to learn. The fewer data We have, less patterns the model can learn, and It tends to overfit with because there is too much noise. A great way to deal with this is group categorical levels of features together based on  some criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, only the categorical columns (object) are analysed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>on_demand</th>\n",
       "      <th>shopper_id</th>\n",
       "      <th>store_branch_id</th>\n",
       "      <th>seniority</th>\n",
       "      <th>store_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e750294655c2c7c34d83cc3181c09de4</td>\n",
       "      <td>True</td>\n",
       "      <td>e63bc83a1a952fa2b3cc9d558fb943cf</td>\n",
       "      <td>65ded5353c5ee48d0b7d48c591b8f430</td>\n",
       "      <td>6c90661e6d2c7579f5ce337c3391dbb9</td>\n",
       "      <td>c4ca4238a0b923820dcc509a6f75849b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6581174846221cb6c467348e87f57641</td>\n",
       "      <td>False</td>\n",
       "      <td>195f9e9d84a4ba9033c4b6a756334d8b</td>\n",
       "      <td>45fbc6d3e05ebd93369ce542e8f2322d</td>\n",
       "      <td>41dc7c9e385c4d2b6c1f7836973951bf</td>\n",
       "      <td>c4ca4238a0b923820dcc509a6f75849b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3a226ea48debc0a7ae9950d5540f2f34</td>\n",
       "      <td>True</td>\n",
       "      <td>a5b9ddc0d82e61582fca19ad43dbaacb</td>\n",
       "      <td>07563a3fe3bbe7e3ba84431ad9d055af</td>\n",
       "      <td>50e13ee63f086c2fe84229348bc91b5b</td>\n",
       "      <td>c4ca4238a0b923820dcc509a6f75849b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7d2ed03fe4966083e74b12694b1669d8</td>\n",
       "      <td>True</td>\n",
       "      <td>d0b3f6bf7e249e5ebb8d3129341773a2</td>\n",
       "      <td>f1748d6b0fd9d439f71450117eba2725</td>\n",
       "      <td>41dc7c9e385c4d2b6c1f7836973951bf</td>\n",
       "      <td>f718499c1c8cef6730f9fd03c8125cab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b4b2682d77118155fe4716300ccf7f39</td>\n",
       "      <td>False</td>\n",
       "      <td>5c5199ce02f7b77caa9c2590a39ad27d</td>\n",
       "      <td>1f0e3dad99908345f7439f8ffabdffc4</td>\n",
       "      <td>50e13ee63f086c2fe84229348bc91b5b</td>\n",
       "      <td>c4ca4238a0b923820dcc509a6f75849b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id on_demand  \\\n",
       "0  e750294655c2c7c34d83cc3181c09de4      True   \n",
       "1  6581174846221cb6c467348e87f57641     False   \n",
       "2  3a226ea48debc0a7ae9950d5540f2f34      True   \n",
       "3  7d2ed03fe4966083e74b12694b1669d8      True   \n",
       "4  b4b2682d77118155fe4716300ccf7f39     False   \n",
       "\n",
       "                         shopper_id                   store_branch_id  \\\n",
       "0  e63bc83a1a952fa2b3cc9d558fb943cf  65ded5353c5ee48d0b7d48c591b8f430   \n",
       "1  195f9e9d84a4ba9033c4b6a756334d8b  45fbc6d3e05ebd93369ce542e8f2322d   \n",
       "2  a5b9ddc0d82e61582fca19ad43dbaacb  07563a3fe3bbe7e3ba84431ad9d055af   \n",
       "3  d0b3f6bf7e249e5ebb8d3129341773a2  f1748d6b0fd9d439f71450117eba2725   \n",
       "4  5c5199ce02f7b77caa9c2590a39ad27d  1f0e3dad99908345f7439f8ffabdffc4   \n",
       "\n",
       "                          seniority                          store_id  \n",
       "0  6c90661e6d2c7579f5ce337c3391dbb9  c4ca4238a0b923820dcc509a6f75849b  \n",
       "1  41dc7c9e385c4d2b6c1f7836973951bf  c4ca4238a0b923820dcc509a6f75849b  \n",
       "2  50e13ee63f086c2fe84229348bc91b5b  c4ca4238a0b923820dcc509a6f75849b  \n",
       "3  41dc7c9e385c4d2b6c1f7836973951bf  f718499c1c8cef6730f9fd03c8125cab  \n",
       "4  50e13ee63f086c2fe84229348bc91b5b  c4ca4238a0b923820dcc509a6f75849b  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orders.select_dtypes(include='O').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_rare_levels = check_rare_levels(df_orders, columns=df_orders.select_dtypes(include='O').columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'order_id': 0.0001,\n",
       " 'on_demand': 0.4547,\n",
       " 'shopper_id': 0.0001,\n",
       " 'store_branch_id': 0.0001,\n",
       " 'seniority': 0.0117,\n",
       " 'store_id': 0.0001}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_rare_levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "id features are not going to be used in the model, so let's ignore them for a while. The others include `on_demand` and `seniority`. `on_demand` seems to be balanced (almost half of True and half of False), but `seniority` has a rare level of category. Let's investigate It."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6c90661e6d2c7579f5ce337c3391dbb9    0.6162\n",
       "50e13ee63f086c2fe84229348bc91b5b    0.2214\n",
       "41dc7c9e385c4d2b6c1f7836973951bf    0.1507\n",
       "bb29b8d0d196b5db5a5350e5e3ae2b1f    0.0117\n",
       "Name: seniority, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orders['seniority'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here We see We have 4 posible values for `seniority`, but one of them may be underrepresented. Let's see the mean of the target within each of these levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seniority</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41dc7c9e385c4d2b6c1f7836973951bf</th>\n",
       "      <td>1207.0</td>\n",
       "      <td>81.781189</td>\n",
       "      <td>37.221665</td>\n",
       "      <td>18.192689</td>\n",
       "      <td>52.639455</td>\n",
       "      <td>74.872787</td>\n",
       "      <td>104.100100</td>\n",
       "      <td>287.907109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50e13ee63f086c2fe84229348bc91b5b</th>\n",
       "      <td>1788.0</td>\n",
       "      <td>80.629333</td>\n",
       "      <td>36.740545</td>\n",
       "      <td>20.331018</td>\n",
       "      <td>53.469808</td>\n",
       "      <td>72.586850</td>\n",
       "      <td>100.232315</td>\n",
       "      <td>285.964774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6c90661e6d2c7579f5ce337c3391dbb9</th>\n",
       "      <td>4904.0</td>\n",
       "      <td>80.928438</td>\n",
       "      <td>33.125084</td>\n",
       "      <td>11.969489</td>\n",
       "      <td>56.262478</td>\n",
       "      <td>75.247718</td>\n",
       "      <td>99.480622</td>\n",
       "      <td>304.190303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bb29b8d0d196b5db5a5350e5e3ae2b1f</th>\n",
       "      <td>101.0</td>\n",
       "      <td>90.107319</td>\n",
       "      <td>41.328242</td>\n",
       "      <td>19.582987</td>\n",
       "      <td>58.809189</td>\n",
       "      <td>79.830846</td>\n",
       "      <td>117.737959</td>\n",
       "      <td>212.658895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   count       mean        std        min  \\\n",
       "seniority                                                                   \n",
       "41dc7c9e385c4d2b6c1f7836973951bf  1207.0  81.781189  37.221665  18.192689   \n",
       "50e13ee63f086c2fe84229348bc91b5b  1788.0  80.629333  36.740545  20.331018   \n",
       "6c90661e6d2c7579f5ce337c3391dbb9  4904.0  80.928438  33.125084  11.969489   \n",
       "bb29b8d0d196b5db5a5350e5e3ae2b1f   101.0  90.107319  41.328242  19.582987   \n",
       "\n",
       "                                        25%        50%         75%         max  \n",
       "seniority                                                                       \n",
       "41dc7c9e385c4d2b6c1f7836973951bf  52.639455  74.872787  104.100100  287.907109  \n",
       "50e13ee63f086c2fe84229348bc91b5b  53.469808  72.586850  100.232315  285.964774  \n",
       "6c90661e6d2c7579f5ce337c3391dbb9  56.262478  75.247718   99.480622  304.190303  \n",
       "bb29b8d0d196b5db5a5350e5e3ae2b1f  58.809189  79.830846  117.737959  212.658895  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orders.groupby('seniority')['total_minutes'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems the rarer level is very associated to the target. So, in modeling step We're going to test if the model is able to learn something from these registers. We can compare performance of the model for each level and see if the model underperfoms in this rarer level. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7) Duplicate Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to avoid the same row appears in train, test or even in the validation set and this turns out to lead to the overestimation of performance, We have to drop duplicates before splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separe id columns (they will not be considered to check for duplicates)\n",
    "id_columns = {'order_id', 'store_branch_id', 'shopper_id', 'store_id'}\n",
    "all_columns = set(df_orders.columns.tolist())\n",
    "columns = all_columns.difference(id_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of duplicate rows\n",
    "df_orders[columns].duplicated(keep=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(df_orders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "# drop_duplicates to assure there is no duplicate\n",
    "df_orders.drop_duplicates(subset=columns, inplace=True)\n",
    "print(len(df_orders))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, there is no duplicate row in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8 Duplicate Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, We need to check if there is duplicate columns. In this little dataset is easy to see that, but In a larger dataset with hundreds or thousands of columns, We would have to check It with an algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to relieve my conscience..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We transpose the dataframe, so that columns are rows. Now We can compare row by row (column by column) to check if there are duplicates\n",
    "df_orders.T.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, there is no duplicate column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a6f7b07b20f4cf172f035b867796e18e995318450c83b6d17ec9b748e82eefe6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('case_cornershop_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
