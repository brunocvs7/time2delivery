{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering & Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step We're gonna to explore our features in order to create new and more significant features. Besides, We'll look for parterns that may help us to solve the challange and include these parterns in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libs\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from haversine import haversine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Env variables and data\n",
    "load_dotenv(find_dotenv())\n",
    "DATA_INPUT_PATH = os.getenv('DATA_PROCESSED_PATH')\n",
    "DATA_TRAIN_NAME = 'train'\n",
    "DATA_TEST_NAME = 'test'\n",
    "# Data\n",
    "df_orders_train = pd.read_parquet(os.path.join(DATA_INPUT_PATH, DATA_TRAIN_NAME))\n",
    "df_orders_test = pd.read_parquet(os.path.join(DATA_INPUT_PATH, DATA_TEST_NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1) Time Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As We have the promised time, We can use information from It as a proxy to the time the order was made. Hence, We are  going to be able to extract hour, day, month, week, and all other characteristics about the time and provide them to the model to learn patterns about It and how those characteristics relates to total minutes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orders_train['hour'] = df_orders_train['promised_time'].apply(lambda x: x.hour)\n",
    "df_orders_train['day'] = df_orders_train['promised_time'].apply(lambda x: x.dayofweek)\n",
    "df_orders_train['month'] = df_orders_train['promised_time'].apply(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2) Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should calculate distance between store and consumer, so that We can have a clue about the time will take to complete the order.To acomplish this, We'll be using the Harvesine function of sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orders_train['distance_km'] = df_orders_train.apply(lambda x: haversine((x['lat_os'], x['lng_os']), \n",
    "                                                                          (x['lat_strb'], x['lng_strb'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['order_id', 'lat_os', 'lng_os', 'promised_time', 'on_demand',\n",
       "       'shopper_id', 'store_branch_id', 'total_minutes', 'seniority',\n",
       "       'found_rate', 'picking_speed', 'accepted_rate', 'rating', 'store_id',\n",
       "       'lat_strb', 'lng_strb', 'sum_kgs', 'sum_unities', 'n_distinct_items',\n",
       "       'hour', 'day', 'month', 'distance_km'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orders_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before We proceed, I'll drop unuseful features (those that represent IDs, lat/long and promised time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orders_train.drop(['order_id', 'lat_os', 'lng_os', 'promised_time', \n",
    "                      'shopper_id', 'store_branch_id', 'lat_strb', 'lng_strb', 'store_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's state some hypothesis and try to check them using statistics and visualization."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a6f7b07b20f4cf172f035b867796e18e995318450c83b6d17ec9b748e82eefe6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('case_cornershop_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
