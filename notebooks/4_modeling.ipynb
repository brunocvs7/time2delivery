{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libs\n",
    "import os\n",
    "import warnings\n",
    "import pickle\n",
    "import optuna\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression, QuantileRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error\n",
    "from utils.features.build import build_distance, build_hour_group\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from ngboost import NGBRegressor\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "from ngboost.distns import Exponential, Normal, LogNormal\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from utils.models.evaluate import plot_learning_curve, plot_permutation_importance\n",
    "from utils.models.predict_model import get_intervals\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Env variables and data\n",
    "load_dotenv(find_dotenv())\n",
    "DATA_INPUT_PATH = os.getenv('DATA_PROCESSED_PATH')\n",
    "DATA_TRAIN_NAME = 'train_best_features'\n",
    "DATA_TEST_NAME = 'test'\n",
    "DATA_SUBMISSION = 'submission'\n",
    "MODEL_PATH = os.getenv('MODEL_PATH')\n",
    "# Data\n",
    "df_orders_train = pd.read_parquet(os.path.join(DATA_INPUT_PATH, DATA_TRAIN_NAME))\n",
    "df_orders_test = pd.read_parquet(os.path.join(DATA_INPUT_PATH, DATA_TEST_NAME))\n",
    "df_submission = pd.read_parquet(os.path.join(DATA_INPUT_PATH, DATA_SUBMISSION))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step We'll try 3 approaches to solve the problem:\n",
    "- Linear Regression \n",
    "- Random Forest \n",
    "- NGBoost "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Linear Regression We intend to create a baseline to be beaten. We'll observe performance in terms of Mean Absolute Percentage Error and Proportion of overestimated predictions. \n",
    "The former metric will be better if It approaches 0, the latter will be better if When model gets It wrong, the model overestimates instead of underestimate. We wish this property because When the model underestimate, the order will be late, and It is better to be early than late. As We saw in Exploratory Data Analysis, the `total_minutes` distribution has a long tail, so It may be import to apply logarithm in order to relieve the impact of outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating X and y for training\n",
    "X_train = df_orders_train.drop('total_minutes', axis=1)\n",
    "y_train = df_orders_train['total_minutes']\n",
    "# list with all columns\n",
    "all_columns = X_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1) Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will have 3 imputers: Median for some numerical, Mode for categorical and 0 for some numerical\n",
    "median_impute_columns_indexes = [all_columns.index(x) for x in ['n_distinct_items', 'distance_km', 'found_rate']]\n",
    "mode_impute_columns_indexes = [all_columns.index(x) for x in ['on_demand', 'hour_group']]\n",
    "zero_impute_columns_indexes = [all_columns.index(x) for x in ['sum_kgs', 'sum_unities']]\n",
    "cat_columns = df_orders_train.select_dtypes(include=['O']).columns.tolist()\n",
    "cat_columns_indexes = [all_columns.index(x) for x in cat_columns]\n",
    "num_columns = df_orders_train.drop('total_minutes', axis=1).select_dtypes(include=['int32', 'int64', 'float32', 'float64']).columns.tolist()\n",
    "num_columns_indexes = [all_columns.index(x) for x in num_columns]\n",
    "impute_median_columns = ['n_distinct_items', 'distance_km', 'found_rate']\n",
    "impute_zero_columns = ['sum_kgs', 'sum_unities']\n",
    "# Feature engineering steps\n",
    "distance_transformer = FunctionTransformer(func=build_distance)\n",
    "hour_group_transformer = FunctionTransformer(func=build_hour_group)\n",
    "pipe_feature_engineering = Pipeline(steps=[('distance_transformer', distance_transformer),\n",
    "                                           ('hor_group_transformer', hour_group_transformer)])\n",
    "# Imputation Steps\n",
    "\n",
    "impute_median = Pipeline([('impute_median', SimpleImputer(strategy='median'))])\n",
    "impute_mode = Pipeline([('impute_mode', SimpleImputer(strategy='most_frequent'))])\n",
    "impute_zero = Pipeline([('impute_zero', SimpleImputer(strategy='constant', fill_value=0))])\n",
    "one_hot = Pipeline([('cat_encoder', OneHotEncoder(handle_unknown='ignore'))])\n",
    "cat_transformer= Pipeline([('impute_mode', impute_mode),                                \n",
    "                           ('one_hot', one_hot)])\n",
    "preprocessor = ColumnTransformer([('impute_mode_one_hot', cat_transformer, cat_columns),\n",
    "                                      ('impute_median', impute_median, impute_median_columns),\n",
    "                                      ('impute_zero', impute_zero, impute_zero_columns)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2) Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our baseline will be a Linear Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline with preprocessor and Model\n",
    "model_baseline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                  ('model', TransformedTargetRegressor(LinearRegression(), func=np.log, inverse_func=np.exp))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing a 10-Fold cross validation to get an estimate for MAE and MAPE\n",
    "df_baseline_cv_metrics = pd.DataFrame(cross_validate(model_baseline,\n",
    "                                        X_train,\n",
    "                                        y_train, \n",
    "                                        scoring=['neg_mean_absolute_error', 'neg_mean_absolute_percentage_error'], \n",
    "                                        return_train_score=True, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_neg_mean_absolute_error</th>\n",
       "      <th>train_neg_mean_absolute_error</th>\n",
       "      <th>test_neg_mean_absolute_percentage_error</th>\n",
       "      <th>train_neg_mean_absolute_percentage_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028925</td>\n",
       "      <td>0.007145</td>\n",
       "      <td>-20.022554</td>\n",
       "      <td>-20.415693</td>\n",
       "      <td>-0.265349</td>\n",
       "      <td>-0.267731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.031672</td>\n",
       "      <td>0.010745</td>\n",
       "      <td>-19.512231</td>\n",
       "      <td>-20.478940</td>\n",
       "      <td>-0.262205</td>\n",
       "      <td>-0.268664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.025328</td>\n",
       "      <td>0.008022</td>\n",
       "      <td>-20.663146</td>\n",
       "      <td>-20.334302</td>\n",
       "      <td>-0.270654</td>\n",
       "      <td>-0.267280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.019351</td>\n",
       "      <td>0.007095</td>\n",
       "      <td>-19.108091</td>\n",
       "      <td>-20.530233</td>\n",
       "      <td>-0.247190</td>\n",
       "      <td>-0.269626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016797</td>\n",
       "      <td>0.006401</td>\n",
       "      <td>-20.154597</td>\n",
       "      <td>-20.398224</td>\n",
       "      <td>-0.280051</td>\n",
       "      <td>-0.267034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.018591</td>\n",
       "      <td>0.008016</td>\n",
       "      <td>-21.316906</td>\n",
       "      <td>-20.262441</td>\n",
       "      <td>-0.266537</td>\n",
       "      <td>-0.267155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.018770</td>\n",
       "      <td>0.006258</td>\n",
       "      <td>-20.798057</td>\n",
       "      <td>-20.336376</td>\n",
       "      <td>-0.271078</td>\n",
       "      <td>-0.267501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.018125</td>\n",
       "      <td>0.007997</td>\n",
       "      <td>-21.100928</td>\n",
       "      <td>-20.275357</td>\n",
       "      <td>-0.276072</td>\n",
       "      <td>-0.266705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.019429</td>\n",
       "      <td>0.006332</td>\n",
       "      <td>-20.361290</td>\n",
       "      <td>-20.383473</td>\n",
       "      <td>-0.269171</td>\n",
       "      <td>-0.267875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.015115</td>\n",
       "      <td>0.006755</td>\n",
       "      <td>-21.155491</td>\n",
       "      <td>-20.292296</td>\n",
       "      <td>-0.274145</td>\n",
       "      <td>-0.266546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_neg_mean_absolute_error  \\\n",
       "0  0.028925    0.007145                    -20.022554   \n",
       "1  0.031672    0.010745                    -19.512231   \n",
       "2  0.025328    0.008022                    -20.663146   \n",
       "3  0.019351    0.007095                    -19.108091   \n",
       "4  0.016797    0.006401                    -20.154597   \n",
       "5  0.018591    0.008016                    -21.316906   \n",
       "6  0.018770    0.006258                    -20.798057   \n",
       "7  0.018125    0.007997                    -21.100928   \n",
       "8  0.019429    0.006332                    -20.361290   \n",
       "9  0.015115    0.006755                    -21.155491   \n",
       "\n",
       "   train_neg_mean_absolute_error  test_neg_mean_absolute_percentage_error  \\\n",
       "0                     -20.415693                                -0.265349   \n",
       "1                     -20.478940                                -0.262205   \n",
       "2                     -20.334302                                -0.270654   \n",
       "3                     -20.530233                                -0.247190   \n",
       "4                     -20.398224                                -0.280051   \n",
       "5                     -20.262441                                -0.266537   \n",
       "6                     -20.336376                                -0.271078   \n",
       "7                     -20.275357                                -0.276072   \n",
       "8                     -20.383473                                -0.269171   \n",
       "9                     -20.292296                                -0.274145   \n",
       "\n",
       "   train_neg_mean_absolute_percentage_error  \n",
       "0                                 -0.267731  \n",
       "1                                 -0.268664  \n",
       "2                                 -0.267280  \n",
       "3                                 -0.269626  \n",
       "4                                 -0.267034  \n",
       "5                                 -0.267155  \n",
       "6                                 -0.267501  \n",
       "7                                 -0.266705  \n",
       "8                                 -0.267875  \n",
       "9                                 -0.266546  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_baseline_cv_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('impute_mode_one_hot',\n",
       "                                                  Pipeline(steps=[('impute_mode',\n",
       "                                                                   Pipeline(steps=[('impute_mode',\n",
       "                                                                                    SimpleImputer(strategy='most_frequent'))])),\n",
       "                                                                  ('one_hot',\n",
       "                                                                   Pipeline(steps=[('cat_encoder',\n",
       "                                                                                    OneHotEncoder(handle_unknown='ignore'))]))]),\n",
       "                                                  ['on_demand', 'hour_group']),\n",
       "                                                 ('impute_median',\n",
       "                                                  Pipeline(steps=[('impute_median',\n",
       "                                                                   SimpleImputer(strategy='median'))]),\n",
       "                                                  ['n_distinct_items',\n",
       "                                                   'distance_km',\n",
       "                                                   'found_rate']),\n",
       "                                                 ('impute_zero',\n",
       "                                                  Pipeline(steps=[('impute_zero',\n",
       "                                                                   SimpleImputer(fill_value=0,\n",
       "                                                                                 strategy='constant'))]),\n",
       "                                                  ['sum_kgs',\n",
       "                                                   'sum_unities'])])),\n",
       "                ('model',\n",
       "                 TransformedTargetRegressor(func=<ufunc 'log'>,\n",
       "                                            inverse_func=<ufunc 'exp'>,\n",
       "                                            regressor=LinearRegression()))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_baseline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see average MAPE and Standard Deviation of MAPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MAPE - Cross Validation Test: -0.26824515384366066\n",
      "Standard Deviation of MAPE - Cross Validation Test: 0.009075169386691588\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average MAPE - Cross Validation Test: {df_baseline_cv_metrics['test_neg_mean_absolute_percentage_error'].mean()}\")\n",
    "print(f\"Standard Deviation of MAPE - Cross Validation Test: {df_baseline_cv_metrics['test_neg_mean_absolute_percentage_error'].std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, nn average, the model is wrong by 26.8%. It means that for an order that will take 100 minutes to finish, It tends to predict either 127 or 73 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, We need to see if the predictions are higher or lower than the real value. It's better to overestimate the time, because the order will not be late. Let's check what happens more in our case, overestimate or underestimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About 51.33333333333333% of our predictions are higher than the real value\n"
     ]
    }
   ],
   "source": [
    "# Generating predictions for X_train\n",
    "y_train_baseline_predict = model_baseline.predict(X_train)\n",
    "# Calculating proportion of overestimation\n",
    "print(f'About {((y_train_baseline_predict >= y_train).sum())/len(y_train)*100}% of our predictions are higher than the real value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2) Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a challenger to the baseline, We will train a Random Forest Regressor with Bayesian Optimization to tuning the hyperparameters. This model will have higher variance compared to Linear Regression and We'll focus on improving MAPE and also try to improve the rate of overestimated orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-08 20:49:28,665]\u001b[0m A new study created in memory with name: no-name-a674b956-0aaa-4b60-9ecc-4a28d3dd1935\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:49:52,503]\u001b[0m Trial 0 finished with value: -0.10527233423177336 and parameters: {'max_depth': 5, 'max_leaf_nodes': 695, 'n_estimators': 896}. Best is trial 0 with value: -0.10527233423177336.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:50:00,956]\u001b[0m Trial 1 finished with value: -0.10404329702450399 and parameters: {'max_depth': 7, 'max_leaf_nodes': 768, 'n_estimators': 241}. Best is trial 1 with value: -0.10404329702450399.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:50:07,195]\u001b[0m Trial 2 finished with value: -0.10527876144281725 and parameters: {'max_depth': 5, 'max_leaf_nodes': 903, 'n_estimators': 223}. Best is trial 1 with value: -0.10404329702450399.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:50:19,524]\u001b[0m Trial 3 finished with value: -0.10425451776810975 and parameters: {'max_depth': 6, 'max_leaf_nodes': 866, 'n_estimators': 412}. Best is trial 1 with value: -0.10404329702450399.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:50:22,032]\u001b[0m Trial 4 finished with value: -0.12112356614051518 and parameters: {'max_depth': 2, 'max_leaf_nodes': 793, 'n_estimators': 157}. Best is trial 1 with value: -0.10404329702450399.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:50:40,883]\u001b[0m Trial 5 finished with value: -0.10403780851184882 and parameters: {'max_depth': 7, 'max_leaf_nodes': 809, 'n_estimators': 541}. Best is trial 5 with value: -0.10403780851184882.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:51:10,157]\u001b[0m Trial 6 finished with value: -0.1042716237981927 and parameters: {'max_depth': 6, 'max_leaf_nodes': 783, 'n_estimators': 985}. Best is trial 5 with value: -0.10403780851184882.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:51:12,489]\u001b[0m Trial 7 finished with value: -0.10539955163467778 and parameters: {'max_depth': 9, 'max_leaf_nodes': 887, 'n_estimators': 51}. Best is trial 5 with value: -0.10403780851184882.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:51:32,188]\u001b[0m Trial 8 finished with value: -0.10528145098626784 and parameters: {'max_depth': 5, 'max_leaf_nodes': 849, 'n_estimators': 769}. Best is trial 5 with value: -0.10403780851184882.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:51:53,772]\u001b[0m Trial 9 finished with value: -0.10426588268950987 and parameters: {'max_depth': 8, 'max_leaf_nodes': 702, 'n_estimators': 553}. Best is trial 5 with value: -0.10403780851184882.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:52:25,668]\u001b[0m Trial 10 finished with value: -0.10529526884454814 and parameters: {'max_depth': 10, 'max_leaf_nodes': 834, 'n_estimators': 698}. Best is trial 5 with value: -0.10403780851184882.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:52:29,176]\u001b[0m Trial 11 finished with value: -0.10425066752727345 and parameters: {'max_depth': 6, 'max_leaf_nodes': 664, 'n_estimators': 97}. Best is trial 5 with value: -0.10403780851184882.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:52:41,008]\u001b[0m Trial 12 finished with value: -0.10765376349791471 and parameters: {'max_depth': 4, 'max_leaf_nodes': 689, 'n_estimators': 508}. Best is trial 5 with value: -0.10403780851184882.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:52:46,797]\u001b[0m Trial 13 finished with value: -0.10483295986735422 and parameters: {'max_depth': 9, 'max_leaf_nodes': 753, 'n_estimators': 140}. Best is trial 5 with value: -0.10403780851184882.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:52:54,607]\u001b[0m Trial 14 finished with value: -0.1339061791017331 and parameters: {'max_depth': 1, 'max_leaf_nodes': 886, 'n_estimators': 820}. Best is trial 5 with value: -0.10403780851184882.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:53:20,384]\u001b[0m Trial 15 finished with value: -0.10429712531607191 and parameters: {'max_depth': 8, 'max_leaf_nodes': 961, 'n_estimators': 727}. Best is trial 5 with value: -0.10403780851184882.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:53:26,143]\u001b[0m Trial 16 finished with value: -0.10421685515436743 and parameters: {'max_depth': 6, 'max_leaf_nodes': 795, 'n_estimators': 198}. Best is trial 5 with value: -0.10403780851184882.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:53:43,212]\u001b[0m Trial 17 finished with value: -0.10402806589669558 and parameters: {'max_depth': 7, 'max_leaf_nodes': 795, 'n_estimators': 519}. Best is trial 17 with value: -0.10402806589669558.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:53:53,298]\u001b[0m Trial 18 finished with value: -0.13388422014215343 and parameters: {'max_depth': 1, 'max_leaf_nodes': 671, 'n_estimators': 961}. Best is trial 17 with value: -0.10402806589669558.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:54:15,505]\u001b[0m Trial 19 finished with value: -0.10530294808900793 and parameters: {'max_depth': 10, 'max_leaf_nodes': 864, 'n_estimators': 459}. Best is trial 17 with value: -0.10402806589669558.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:54:37,302]\u001b[0m Trial 20 finished with value: -0.10405893191702005 and parameters: {'max_depth': 7, 'max_leaf_nodes': 813, 'n_estimators': 672}. Best is trial 17 with value: -0.10402806589669558.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:54:50,881]\u001b[0m Trial 21 finished with value: -0.10425992780468754 and parameters: {'max_depth': 6, 'max_leaf_nodes': 790, 'n_estimators': 479}. Best is trial 17 with value: -0.10402806589669558.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:55:03,356]\u001b[0m Trial 22 finished with value: -0.1042609381835212 and parameters: {'max_depth': 8, 'max_leaf_nodes': 773, 'n_estimators': 349}. Best is trial 17 with value: -0.10402806589669558.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:55:12,497]\u001b[0m Trial 23 finished with value: -0.11235602553430472 and parameters: {'max_depth': 3, 'max_leaf_nodes': 844, 'n_estimators': 524}. Best is trial 17 with value: -0.10402806589669558.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:55:24,651]\u001b[0m Trial 24 finished with value: -0.1047627081946741 and parameters: {'max_depth': 9, 'max_leaf_nodes': 637, 'n_estimators': 305}. Best is trial 17 with value: -0.10402806589669558.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:55:36,764]\u001b[0m Trial 25 finished with value: -0.10402238194462195 and parameters: {'max_depth': 7, 'max_leaf_nodes': 948, 'n_estimators': 368}. Best is trial 25 with value: -0.10402238194462195.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:55:51,769]\u001b[0m Trial 26 finished with value: -0.10425819518958879 and parameters: {'max_depth': 6, 'max_leaf_nodes': 922, 'n_estimators': 513}. Best is trial 25 with value: -0.10402238194462195.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:56:04,241]\u001b[0m Trial 27 finished with value: -0.10424921603993102 and parameters: {'max_depth': 8, 'max_leaf_nodes': 937, 'n_estimators': 346}. Best is trial 25 with value: -0.10402238194462195.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:56:14,838]\u001b[0m Trial 28 finished with value: -0.10427702781256268 and parameters: {'max_depth': 8, 'max_leaf_nodes': 1000, 'n_estimators': 304}. Best is trial 25 with value: -0.10402238194462195.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:56:20,541]\u001b[0m Trial 29 finished with value: -0.12117365975162361 and parameters: {'max_depth': 2, 'max_leaf_nodes': 995, 'n_estimators': 440}. Best is trial 25 with value: -0.10402238194462195.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:56:50,576]\u001b[0m Trial 30 finished with value: -0.10473884115913945 and parameters: {'max_depth': 9, 'max_leaf_nodes': 731, 'n_estimators': 776}. Best is trial 25 with value: -0.10402238194462195.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:56:58,525]\u001b[0m Trial 31 finished with value: -0.10406831446390677 and parameters: {'max_depth': 7, 'max_leaf_nodes': 810, 'n_estimators': 250}. Best is trial 25 with value: -0.10402238194462195.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:57:20,243]\u001b[0m Trial 32 finished with value: -0.1052800423063017 and parameters: {'max_depth': 5, 'max_leaf_nodes': 601, 'n_estimators': 873}. Best is trial 25 with value: -0.10402238194462195.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:57:27,657]\u001b[0m Trial 33 finished with value: -0.10524630557940862 and parameters: {'max_depth': 5, 'max_leaf_nodes': 966, 'n_estimators': 286}. Best is trial 25 with value: -0.10402238194462195.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:57:45,707]\u001b[0m Trial 34 finished with value: -0.10427341977058813 and parameters: {'max_depth': 8, 'max_leaf_nodes': 784, 'n_estimators': 499}. Best is trial 25 with value: -0.10402238194462195.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:58:00,533]\u001b[0m Trial 35 finished with value: -0.1040472344873895 and parameters: {'max_depth': 7, 'max_leaf_nodes': 885, 'n_estimators': 470}. Best is trial 25 with value: -0.10402238194462195.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:58:11,352]\u001b[0m Trial 36 finished with value: -0.10525291959759209 and parameters: {'max_depth': 5, 'max_leaf_nodes': 773, 'n_estimators': 440}. Best is trial 25 with value: -0.10402238194462195.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:58:20,299]\u001b[0m Trial 37 finished with value: -0.10423804846530656 and parameters: {'max_depth': 6, 'max_leaf_nodes': 701, 'n_estimators': 316}. Best is trial 25 with value: -0.10402238194462195.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:58:39,311]\u001b[0m Trial 38 finished with value: -0.1042709794710813 and parameters: {'max_depth': 6, 'max_leaf_nodes': 713, 'n_estimators': 668}. Best is trial 25 with value: -0.10402238194462195.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:58:57,207]\u001b[0m Trial 39 finished with value: -0.1040419713325768 and parameters: {'max_depth': 7, 'max_leaf_nodes': 802, 'n_estimators': 558}. Best is trial 25 with value: -0.10402238194462195.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:58:58,398]\u001b[0m Trial 40 finished with value: -0.1338098575637961 and parameters: {'max_depth': 1, 'max_leaf_nodes': 667, 'n_estimators': 111}. Best is trial 25 with value: -0.10402238194462195.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:59:15,563]\u001b[0m Trial 41 finished with value: -0.10403675149317793 and parameters: {'max_depth': 7, 'max_leaf_nodes': 843, 'n_estimators': 544}. Best is trial 25 with value: -0.10402238194462195.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:59:34,253]\u001b[0m Trial 42 finished with value: -0.10427111814787093 and parameters: {'max_depth': 6, 'max_leaf_nodes': 838, 'n_estimators': 662}. Best is trial 25 with value: -0.10402238194462195.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 20:59:50,498]\u001b[0m Trial 43 finished with value: -0.1042543018998698 and parameters: {'max_depth': 8, 'max_leaf_nodes': 819, 'n_estimators': 459}. Best is trial 25 with value: -0.10402238194462195.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 21:00:13,510]\u001b[0m Trial 44 finished with value: -0.1042586122457789 and parameters: {'max_depth': 8, 'max_leaf_nodes': 860, 'n_estimators': 641}. Best is trial 25 with value: -0.10402238194462195.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 21:00:30,976]\u001b[0m Trial 45 finished with value: -0.1040255645255272 and parameters: {'max_depth': 7, 'max_leaf_nodes': 783, 'n_estimators': 526}. Best is trial 25 with value: -0.10402238194462195.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 21:00:50,258]\u001b[0m Trial 46 finished with value: -0.10426138449860449 and parameters: {'max_depth': 8, 'max_leaf_nodes': 742, 'n_estimators': 524}. Best is trial 25 with value: -0.10402238194462195.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 21:01:15,237]\u001b[0m Trial 47 finished with value: -0.10526771494108049 and parameters: {'max_depth': 5, 'max_leaf_nodes': 996, 'n_estimators': 976}. Best is trial 25 with value: -0.10402238194462195.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 21:01:33,638]\u001b[0m Trial 48 finished with value: -0.10426803587744563 and parameters: {'max_depth': 6, 'max_leaf_nodes': 773, 'n_estimators': 647}. Best is trial 25 with value: -0.10402238194462195.\u001b[0m\n",
      "\u001b[32m[I 2021-12-08 21:01:49,377]\u001b[0m Trial 49 finished with value: -0.10425613172791151 and parameters: {'max_depth': 6, 'max_leaf_nodes': 830, 'n_estimators': 539}. Best is trial 25 with value: -0.10402238194462195.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning using optuna \n",
    "def objective(trial):\n",
    "    params = {'model__regressor__max_depth':trial.suggest_int('max_depth', 1, 10),\n",
    "              'model__regressor__max_leaf_nodes':trial.suggest_int('max_leaf_nodes', 600, 1000),\n",
    "              'model__regressor__n_estimators':trial.suggest_int('n_estimators', 30, 1000)}\n",
    "    \n",
    "    model_rf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                  ('model', TransformedTargetRegressor(RandomForestRegressor(random_state=123), func=np.log, inverse_func=np.exp))])\n",
    "    model_rf.set_params(**params)   \n",
    "    score = cross_val_score(model_rf, X_train, np.log(y_train), cv=5, scoring='neg_mean_squared_error')\n",
    "    mse = score.mean()\n",
    "\n",
    "    return mse\n",
    "sampler = TPESampler(multivariate=True)\n",
    "study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                  ('model', RandomForestRegressor(random_state=123))])\n",
    "model_rf['model'].set_params(**study.best_params)\n",
    "df_rf_cv_metrics = pd.DataFrame(cross_validate(model_rf,\n",
    "                                        X_train,\n",
    "                                        y_train, \n",
    "                                        scoring=['neg_mean_absolute_error', 'neg_mean_absolute_percentage_error'], \n",
    "                                        return_train_score=True, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_neg_mean_absolute_error</th>\n",
       "      <th>train_neg_mean_absolute_error</th>\n",
       "      <th>test_neg_mean_absolute_percentage_error</th>\n",
       "      <th>train_neg_mean_absolute_percentage_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.578422</td>\n",
       "      <td>0.043047</td>\n",
       "      <td>-19.755650</td>\n",
       "      <td>-18.294765</td>\n",
       "      <td>-0.276865</td>\n",
       "      <td>-0.256919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.599762</td>\n",
       "      <td>0.044312</td>\n",
       "      <td>-19.484809</td>\n",
       "      <td>-18.328173</td>\n",
       "      <td>-0.278720</td>\n",
       "      <td>-0.257886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.634121</td>\n",
       "      <td>0.041394</td>\n",
       "      <td>-20.749369</td>\n",
       "      <td>-18.166565</td>\n",
       "      <td>-0.285864</td>\n",
       "      <td>-0.255367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.563715</td>\n",
       "      <td>0.043085</td>\n",
       "      <td>-18.585874</td>\n",
       "      <td>-18.424362</td>\n",
       "      <td>-0.257024</td>\n",
       "      <td>-0.259352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.581132</td>\n",
       "      <td>0.041065</td>\n",
       "      <td>-20.058745</td>\n",
       "      <td>-18.227328</td>\n",
       "      <td>-0.292076</td>\n",
       "      <td>-0.256293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.567649</td>\n",
       "      <td>0.044509</td>\n",
       "      <td>-20.456459</td>\n",
       "      <td>-18.211820</td>\n",
       "      <td>-0.273080</td>\n",
       "      <td>-0.257228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.571286</td>\n",
       "      <td>0.051227</td>\n",
       "      <td>-20.879538</td>\n",
       "      <td>-18.179255</td>\n",
       "      <td>-0.290557</td>\n",
       "      <td>-0.255411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.557800</td>\n",
       "      <td>0.041285</td>\n",
       "      <td>-20.912159</td>\n",
       "      <td>-18.183693</td>\n",
       "      <td>-0.288831</td>\n",
       "      <td>-0.255878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.522886</td>\n",
       "      <td>0.043346</td>\n",
       "      <td>-19.776110</td>\n",
       "      <td>-18.280314</td>\n",
       "      <td>-0.278725</td>\n",
       "      <td>-0.257278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.526025</td>\n",
       "      <td>0.053432</td>\n",
       "      <td>-20.441183</td>\n",
       "      <td>-18.153994</td>\n",
       "      <td>-0.280869</td>\n",
       "      <td>-0.255582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_neg_mean_absolute_error  \\\n",
       "0  2.578422    0.043047                    -19.755650   \n",
       "1  2.599762    0.044312                    -19.484809   \n",
       "2  2.634121    0.041394                    -20.749369   \n",
       "3  2.563715    0.043085                    -18.585874   \n",
       "4  2.581132    0.041065                    -20.058745   \n",
       "5  2.567649    0.044509                    -20.456459   \n",
       "6  2.571286    0.051227                    -20.879538   \n",
       "7  2.557800    0.041285                    -20.912159   \n",
       "8  2.522886    0.043346                    -19.776110   \n",
       "9  2.526025    0.053432                    -20.441183   \n",
       "\n",
       "   train_neg_mean_absolute_error  test_neg_mean_absolute_percentage_error  \\\n",
       "0                     -18.294765                                -0.276865   \n",
       "1                     -18.328173                                -0.278720   \n",
       "2                     -18.166565                                -0.285864   \n",
       "3                     -18.424362                                -0.257024   \n",
       "4                     -18.227328                                -0.292076   \n",
       "5                     -18.211820                                -0.273080   \n",
       "6                     -18.179255                                -0.290557   \n",
       "7                     -18.183693                                -0.288831   \n",
       "8                     -18.280314                                -0.278725   \n",
       "9                     -18.153994                                -0.280869   \n",
       "\n",
       "   train_neg_mean_absolute_percentage_error  \n",
       "0                                 -0.256919  \n",
       "1                                 -0.257886  \n",
       "2                                 -0.255367  \n",
       "3                                 -0.259352  \n",
       "4                                 -0.256293  \n",
       "5                                 -0.257228  \n",
       "6                                 -0.255411  \n",
       "7                                 -0.255878  \n",
       "8                                 -0.257278  \n",
       "9                                 -0.255582  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf_cv_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MAPE - Cross Validation Test: -0.28026104424121495\n",
      "Standard Deviation of MAPE - Cross Validation Test: 0.010320406224479894\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average MAPE - Cross Validation Test: {df_rf_cv_metrics['test_neg_mean_absolute_percentage_error'].mean()}\")\n",
    "print(f\"Standard Deviation of MAPE - Cross Validation Test: {df_rf_cv_metrics['test_neg_mean_absolute_percentage_error'].std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('impute_mode_one_hot',\n",
       "                                                  Pipeline(steps=[('impute_mode',\n",
       "                                                                   Pipeline(steps=[('impute_mode',\n",
       "                                                                                    SimpleImputer(strategy='most_frequent'))])),\n",
       "                                                                  ('one_hot',\n",
       "                                                                   Pipeline(steps=[('cat_encoder',\n",
       "                                                                                    OneHotEncoder(handle_unknown='ignore'))]))]),\n",
       "                                                  ['on_demand', 'hour_group']),\n",
       "                                                 ('impute_median',\n",
       "                                                  Pipeline(steps=[('impute_median',\n",
       "                                                                   SimpleImputer(strategy='median'))]),\n",
       "                                                  ['n_distinct_items',\n",
       "                                                   'distance_km',\n",
       "                                                   'found_rate']),\n",
       "                                                 ('impute_zero',\n",
       "                                                  Pipeline(steps=[('impute_zero',\n",
       "                                                                   SimpleImputer(fill_value=0,\n",
       "                                                                                 strategy='constant'))]),\n",
       "                                                  ['sum_kgs',\n",
       "                                                   'sum_unities'])])),\n",
       "                ('model',\n",
       "                 RandomForestRegressor(max_depth=7, max_leaf_nodes=948,\n",
       "                                       n_estimators=368, random_state=123))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About 57.116666666666674% of our predictions are higher than the real value\n"
     ]
    }
   ],
   "source": [
    "# Generating predictions for X_train\n",
    "y_train_rf_predict = model_rf.predict(X_train)\n",
    "# Calculating proportion of overestimation\n",
    "print(f'About {((y_train_rf_predict >= y_train).sum())/len(y_train)*100}% of our predictions are higher than the real value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that, despite MAPE is a little worse compared to the baseline, the proportion of overestimated predictions is higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3) NGBoost "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, We'll train a NGBoost model, which is capable of outputing a distribution for each prediction, so that We'll be able to calculate prediction interval, what can be really useful in production enviroment, because Cornershop can now give an interval, instead of a point estimation for the time the order will take to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=4.8731 val_loss=0.0000 scale=1.0000 norm=0.6300\n",
      "[iter 100] loss=4.6717 val_loss=0.0000 scale=1.0000 norm=0.5447\n",
      "[iter 200] loss=4.5897 val_loss=0.0000 scale=1.0000 norm=0.5485\n",
      "[iter 300] loss=4.5594 val_loss=0.0000 scale=1.0000 norm=0.5618\n",
      "[iter 400] loss=4.5485 val_loss=0.0000 scale=1.0000 norm=0.5678\n",
      "[iter 0] loss=4.8759 val_loss=0.0000 scale=1.0000 norm=0.6297\n",
      "[iter 100] loss=4.6766 val_loss=0.0000 scale=1.0000 norm=0.5445\n",
      "[iter 200] loss=4.5975 val_loss=0.0000 scale=1.0000 norm=0.5475\n",
      "[iter 300] loss=4.5662 val_loss=0.0000 scale=1.0000 norm=0.5597\n",
      "[iter 400] loss=4.5549 val_loss=0.0000 scale=2.0000 norm=1.1334\n",
      "[iter 0] loss=4.8676 val_loss=0.0000 scale=1.0000 norm=0.6267\n",
      "[iter 100] loss=4.6655 val_loss=0.0000 scale=1.0000 norm=0.5406\n",
      "[iter 200] loss=4.5803 val_loss=0.0000 scale=1.0000 norm=0.5465\n",
      "[iter 300] loss=4.5531 val_loss=0.0000 scale=1.0000 norm=0.5593\n",
      "[iter 400] loss=4.5430 val_loss=0.0000 scale=2.0000 norm=1.1300\n",
      "[iter 0] loss=4.8758 val_loss=0.0000 scale=1.0000 norm=0.6284\n",
      "[iter 100] loss=4.6740 val_loss=0.0000 scale=1.0000 norm=0.5415\n",
      "[iter 200] loss=4.5920 val_loss=0.0000 scale=1.0000 norm=0.5462\n",
      "[iter 300] loss=4.5625 val_loss=0.0000 scale=1.0000 norm=0.5597\n",
      "[iter 400] loss=4.5513 val_loss=0.0000 scale=1.0000 norm=0.5658\n",
      "[iter 0] loss=4.8687 val_loss=0.0000 scale=1.0000 norm=0.6278\n",
      "[iter 100] loss=4.6704 val_loss=0.0000 scale=1.0000 norm=0.5433\n",
      "[iter 200] loss=4.5780 val_loss=0.0000 scale=2.0000 norm=1.1001\n",
      "[iter 300] loss=4.5546 val_loss=0.0000 scale=1.0000 norm=0.5625\n",
      "[iter 400] loss=4.5457 val_loss=0.0000 scale=2.0000 norm=1.1330\n",
      "[iter 0] loss=4.8659 val_loss=0.0000 scale=1.0000 norm=0.6291\n",
      "[iter 100] loss=4.6670 val_loss=0.0000 scale=1.0000 norm=0.5453\n",
      "[iter 200] loss=4.5766 val_loss=0.0000 scale=1.0000 norm=0.5520\n",
      "[iter 300] loss=4.5524 val_loss=0.0000 scale=2.0000 norm=1.1295\n",
      "[iter 400] loss=4.5433 val_loss=0.0000 scale=1.0000 norm=0.5694\n",
      "[iter 0] loss=4.8693 val_loss=0.0000 scale=1.0000 norm=0.6284\n",
      "[iter 100] loss=4.6671 val_loss=0.0000 scale=1.0000 norm=0.5420\n",
      "[iter 200] loss=4.5791 val_loss=0.0000 scale=1.0000 norm=0.5479\n",
      "[iter 300] loss=4.5530 val_loss=0.0000 scale=2.0000 norm=1.1217\n",
      "[iter 400] loss=4.5430 val_loss=0.0000 scale=1.0000 norm=0.5662\n",
      "[iter 0] loss=4.8630 val_loss=0.0000 scale=1.0000 norm=0.6269\n",
      "[iter 100] loss=4.6619 val_loss=0.0000 scale=1.0000 norm=0.5415\n",
      "[iter 200] loss=4.5800 val_loss=0.0000 scale=1.0000 norm=0.5473\n",
      "[iter 300] loss=4.5527 val_loss=0.0000 scale=1.0000 norm=0.5603\n",
      "[iter 400] loss=4.5427 val_loss=0.0000 scale=1.0000 norm=0.5664\n",
      "[iter 0] loss=4.8729 val_loss=0.0000 scale=1.0000 norm=0.6300\n",
      "[iter 100] loss=4.6731 val_loss=0.0000 scale=1.0000 norm=0.5448\n",
      "[iter 200] loss=4.5912 val_loss=0.0000 scale=1.0000 norm=0.5491\n",
      "[iter 300] loss=4.5603 val_loss=0.0000 scale=1.0000 norm=0.5629\n",
      "[iter 400] loss=4.5500 val_loss=0.0000 scale=1.0000 norm=0.5687\n",
      "[iter 0] loss=4.8700 val_loss=0.0000 scale=1.0000 norm=0.6287\n",
      "[iter 100] loss=4.6660 val_loss=0.0000 scale=1.0000 norm=0.5418\n",
      "[iter 200] loss=4.5834 val_loss=0.0000 scale=1.0000 norm=0.5462\n",
      "[iter 300] loss=4.5540 val_loss=0.0000 scale=2.0000 norm=1.1190\n",
      "[iter 400] loss=4.5436 val_loss=0.0000 scale=1.0000 norm=0.5659\n"
     ]
    }
   ],
   "source": [
    "model_nb = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('model',NGBRegressor(Base=DecisionTreeRegressor(max_depth=5, min_samples_leaf=600,random_state=123),\n",
    "                                                 random_state=123,\n",
    "                                                Dist=LogNormal))])\n",
    "df_rf_nb_metrics = pd.DataFrame(cross_validate(model_nb,\n",
    "                                        X_train,\n",
    "                                        y_train, \n",
    "                                        scoring=['neg_mean_absolute_error', 'neg_mean_absolute_percentage_error'], \n",
    "                                        return_train_score=True, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_neg_mean_absolute_error</th>\n",
       "      <th>train_neg_mean_absolute_error</th>\n",
       "      <th>test_neg_mean_absolute_percentage_error</th>\n",
       "      <th>train_neg_mean_absolute_percentage_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.631492</td>\n",
       "      <td>0.112894</td>\n",
       "      <td>-19.877955</td>\n",
       "      <td>-19.931487</td>\n",
       "      <td>-0.276375</td>\n",
       "      <td>-0.274594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.659264</td>\n",
       "      <td>0.118663</td>\n",
       "      <td>-19.136172</td>\n",
       "      <td>-20.036376</td>\n",
       "      <td>-0.271892</td>\n",
       "      <td>-0.276238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.139647</td>\n",
       "      <td>0.108349</td>\n",
       "      <td>-21.170471</td>\n",
       "      <td>-19.800007</td>\n",
       "      <td>-0.286607</td>\n",
       "      <td>-0.273285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.838704</td>\n",
       "      <td>0.108441</td>\n",
       "      <td>-18.852807</td>\n",
       "      <td>-20.015819</td>\n",
       "      <td>-0.257770</td>\n",
       "      <td>-0.276485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.296865</td>\n",
       "      <td>0.104802</td>\n",
       "      <td>-20.453957</td>\n",
       "      <td>-19.853026</td>\n",
       "      <td>-0.293276</td>\n",
       "      <td>-0.273466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.243917</td>\n",
       "      <td>0.114186</td>\n",
       "      <td>-20.642691</td>\n",
       "      <td>-19.814938</td>\n",
       "      <td>-0.272081</td>\n",
       "      <td>-0.274633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12.697415</td>\n",
       "      <td>0.113073</td>\n",
       "      <td>-20.981803</td>\n",
       "      <td>-19.835037</td>\n",
       "      <td>-0.289344</td>\n",
       "      <td>-0.273698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.604541</td>\n",
       "      <td>0.105242</td>\n",
       "      <td>-21.062606</td>\n",
       "      <td>-19.815347</td>\n",
       "      <td>-0.291492</td>\n",
       "      <td>-0.273370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12.602217</td>\n",
       "      <td>0.109197</td>\n",
       "      <td>-19.987676</td>\n",
       "      <td>-19.921240</td>\n",
       "      <td>-0.280282</td>\n",
       "      <td>-0.275080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.422642</td>\n",
       "      <td>0.117842</td>\n",
       "      <td>-20.875762</td>\n",
       "      <td>-19.820506</td>\n",
       "      <td>-0.284186</td>\n",
       "      <td>-0.273671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fit_time  score_time  test_neg_mean_absolute_error  \\\n",
       "0  12.631492    0.112894                    -19.877955   \n",
       "1  12.659264    0.118663                    -19.136172   \n",
       "2  12.139647    0.108349                    -21.170471   \n",
       "3  11.838704    0.108441                    -18.852807   \n",
       "4  12.296865    0.104802                    -20.453957   \n",
       "5  12.243917    0.114186                    -20.642691   \n",
       "6  12.697415    0.113073                    -20.981803   \n",
       "7  12.604541    0.105242                    -21.062606   \n",
       "8  12.602217    0.109197                    -19.987676   \n",
       "9  12.422642    0.117842                    -20.875762   \n",
       "\n",
       "   train_neg_mean_absolute_error  test_neg_mean_absolute_percentage_error  \\\n",
       "0                     -19.931487                                -0.276375   \n",
       "1                     -20.036376                                -0.271892   \n",
       "2                     -19.800007                                -0.286607   \n",
       "3                     -20.015819                                -0.257770   \n",
       "4                     -19.853026                                -0.293276   \n",
       "5                     -19.814938                                -0.272081   \n",
       "6                     -19.835037                                -0.289344   \n",
       "7                     -19.815347                                -0.291492   \n",
       "8                     -19.921240                                -0.280282   \n",
       "9                     -19.820506                                -0.284186   \n",
       "\n",
       "   train_neg_mean_absolute_percentage_error  \n",
       "0                                 -0.274594  \n",
       "1                                 -0.276238  \n",
       "2                                 -0.273285  \n",
       "3                                 -0.276485  \n",
       "4                                 -0.273466  \n",
       "5                                 -0.274633  \n",
       "6                                 -0.273698  \n",
       "7                                 -0.273370  \n",
       "8                                 -0.275080  \n",
       "9                                 -0.273671  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf_nb_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MAPE - Cross Validation Test: -0.2803305443860043\n",
      "Standard Deviation of MAPE - Cross Validation Test: 0.011013031804846442\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average MAPE - Cross Validation Test: {df_rf_nb_metrics['test_neg_mean_absolute_percentage_error'].mean()}\")\n",
    "print(f\"Standard Deviation of MAPE - Cross Validation Test: {df_rf_nb_metrics['test_neg_mean_absolute_percentage_error'].std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=4.8702 val_loss=0.0000 scale=1.0000 norm=0.6286\n",
      "[iter 100] loss=4.6638 val_loss=0.0000 scale=1.0000 norm=0.5410\n",
      "[iter 200] loss=4.5812 val_loss=0.0000 scale=2.0000 norm=1.0922\n",
      "[iter 300] loss=4.5515 val_loss=0.0000 scale=1.0000 norm=0.5613\n",
      "[iter 400] loss=4.5426 val_loss=0.0000 scale=2.0000 norm=1.1339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('impute_mode_one_hot',\n",
       "                                                  Pipeline(steps=[('impute_mode',\n",
       "                                                                   Pipeline(steps=[('impute_mode',\n",
       "                                                                                    SimpleImputer(strategy='most_frequent'))])),\n",
       "                                                                  ('one_hot',\n",
       "                                                                   Pipeline(steps=[('cat_encoder',\n",
       "                                                                                    OneHotEncoder(handle_unknown='ignore'))]))]),\n",
       "                                                  ['on_demand', 'hour_group']),\n",
       "                                                 ('impute_median',\n",
       "                                                  Pipeline(steps=[('impute_...\n",
       "                                                 ('impute_zero',\n",
       "                                                  Pipeline(steps=[('impute_zero',\n",
       "                                                                   SimpleImputer(fill_value=0,\n",
       "                                                                                 strategy='constant'))]),\n",
       "                                                  ['sum_kgs',\n",
       "                                                   'sum_unities'])])),\n",
       "                ('model',\n",
       "                 NGBRegressor(Base=DecisionTreeRegressor(max_depth=5,\n",
       "                                                         min_samples_leaf=600,\n",
       "                                                         random_state=123),\n",
       "                              Dist=<class 'ngboost.distns.distn.Distn.uncensor.<locals>.DistWithUncensoredScore'>,\n",
       "                              random_state=RandomState(MT19937) at 0x16443DB40))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nb.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About 57.41666666666667% of our predictions are higher than the real value\n"
     ]
    }
   ],
   "source": [
    "y_train_nb_predict = model_nb.predict(X_train)\n",
    "print(f'About {((y_train_nb_predict >= y_train).sum())/len(y_train)*100}% of our predictions are higher than the real value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate prediction interval, We'll need to apply `.pred_dist()` method and then extract the distribution parameters for each prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing step\n",
    "X_train_preprocessed = model_nb['preprocessor'].transform(X_train)\n",
    "# get parameters \n",
    "y_train_prob = model_nb['model'].pred_dist(X_train_preprocessed).params\n",
    "predictions = pd.DataFrame(y_train_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s</th>\n",
       "      <th>scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.390934</td>\n",
       "      <td>44.356750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.260647</td>\n",
       "      <td>123.058273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.408346</td>\n",
       "      <td>56.740349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.234675</td>\n",
       "      <td>107.306261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.330448</td>\n",
       "      <td>84.836854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>0.338832</td>\n",
       "      <td>55.881411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>0.327237</td>\n",
       "      <td>75.126496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>0.394121</td>\n",
       "      <td>48.546872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>0.292796</td>\n",
       "      <td>71.703699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>0.261597</td>\n",
       "      <td>82.587356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             s       scale\n",
       "0     0.390934   44.356750\n",
       "1     0.260647  123.058273\n",
       "2     0.408346   56.740349\n",
       "3     0.234675  107.306261\n",
       "4     0.330448   84.836854\n",
       "...        ...         ...\n",
       "5995  0.338832   55.881411\n",
       "5996  0.327237   75.126496\n",
       "5997  0.394121   48.546872\n",
       "5998  0.292796   71.703699\n",
       "5999  0.261597   82.587356\n",
       "\n",
       "[6000 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each row We have `s` and `scale` values. As We defined the target to have a normal distribution, We can apply these parameters and get the interval using `scipy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#create 95% confidence interval \n",
    "predictions['interval'] = predictions.apply(lambda x: st.lognorm.interval(alpha=0.95, s=x['s'], scale=x['scale']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20.615620568217647, 95.43837093908799)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(predictions.loc[0,:]).T['interval'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the interval is pretty large in some cases, which says that We need more data and more features to accomplish the task completely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NGBoost performed worse than `Random Forest Regressor` and `Linear Regression` comparing `MAPE`. When It comes `Overestimation Rate`, NGBoost is the best model. Because the differente in MAPE is not so large between models and Overestimation Rate can impact a lot in User Journey/Experience, We will choose NGBoost. Besides, NGBoost is able to give distributions instead of point estimates, so We'll be able to estimate confidence intervals, that may be more suitable in delivery applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=4.8250 val_loss=0.0000 scale=512.0000 norm=316.1187\n",
      "== Quitting at iteration / GRAD 0\n",
      "[iter 0] loss=4.8493 val_loss=0.0000 scale=1.0000 norm=0.6324\n",
      "[iter 100] loss=4.7143 val_loss=0.0000 scale=2.0000 norm=1.1536\n",
      "[iter 200] loss=4.6614 val_loss=0.0000 scale=1.0000 norm=0.5800\n",
      "[iter 300] loss=4.6381 val_loss=0.0000 scale=2.0000 norm=1.1670\n",
      "[iter 400] loss=4.6246 val_loss=0.0000 scale=2.0000 norm=1.1710\n",
      "[iter 0] loss=4.8654 val_loss=0.0000 scale=1.0000 norm=0.6309\n",
      "[iter 100] loss=4.6833 val_loss=0.0000 scale=1.0000 norm=0.5537\n",
      "[iter 200] loss=4.6179 val_loss=0.0000 scale=1.0000 norm=0.5533\n",
      "[iter 300] loss=4.5859 val_loss=0.0000 scale=1.0000 norm=0.5620\n",
      "[iter 400] loss=4.5711 val_loss=0.0000 scale=1.0000 norm=0.5693\n",
      "[iter 0] loss=4.8773 val_loss=0.0000 scale=1.0000 norm=0.6323\n",
      "[iter 100] loss=4.6774 val_loss=0.0000 scale=1.0000 norm=0.5478\n",
      "[iter 200] loss=4.5970 val_loss=0.0000 scale=2.0000 norm=1.1042\n",
      "[iter 300] loss=4.5677 val_loss=0.0000 scale=1.0000 norm=0.5653\n",
      "[iter 400] loss=4.5568 val_loss=0.0000 scale=1.0000 norm=0.5719\n",
      "[iter 0] loss=4.8731 val_loss=0.0000 scale=1.0000 norm=0.6300\n",
      "[iter 100] loss=4.6717 val_loss=0.0000 scale=1.0000 norm=0.5447\n",
      "[iter 200] loss=4.5897 val_loss=0.0000 scale=1.0000 norm=0.5485\n",
      "[iter 300] loss=4.5594 val_loss=0.0000 scale=1.0000 norm=0.5618\n",
      "[iter 400] loss=4.5485 val_loss=0.0000 scale=1.0000 norm=0.5678\n",
      "[iter 0] loss=4.8487 val_loss=0.0000 scale=256.0000 norm=158.0449\n",
      "== Quitting at iteration / GRAD 0\n",
      "[iter 0] loss=4.8581 val_loss=0.0000 scale=1.0000 norm=0.6313\n",
      "[iter 100] loss=4.7178 val_loss=0.0000 scale=1.0000 norm=0.5740\n",
      "[iter 200] loss=4.6691 val_loss=0.0000 scale=2.0000 norm=1.1546\n",
      "[iter 300] loss=4.6464 val_loss=0.0000 scale=1.0000 norm=0.5801\n",
      "[iter 400] loss=4.6333 val_loss=0.0000 scale=1.0000 norm=0.5818\n",
      "[iter 0] loss=4.8705 val_loss=0.0000 scale=1.0000 norm=0.6303\n",
      "[iter 100] loss=4.6919 val_loss=0.0000 scale=1.0000 norm=0.5519\n",
      "[iter 200] loss=4.6221 val_loss=0.0000 scale=1.0000 norm=0.5498\n",
      "[iter 300] loss=4.5895 val_loss=0.0000 scale=1.0000 norm=0.5585\n",
      "[iter 400] loss=4.5751 val_loss=0.0000 scale=2.0000 norm=1.1300\n",
      "[iter 0] loss=4.8809 val_loss=0.0000 scale=1.0000 norm=0.6319\n",
      "[iter 100] loss=4.6822 val_loss=0.0000 scale=1.0000 norm=0.5467\n",
      "[iter 200] loss=4.6016 val_loss=0.0000 scale=2.0000 norm=1.1023\n",
      "[iter 300] loss=4.5730 val_loss=0.0000 scale=1.0000 norm=0.5637\n",
      "[iter 400] loss=4.5623 val_loss=0.0000 scale=1.0000 norm=0.5702\n",
      "[iter 0] loss=4.8759 val_loss=0.0000 scale=1.0000 norm=0.6297\n",
      "[iter 100] loss=4.6766 val_loss=0.0000 scale=1.0000 norm=0.5445\n",
      "[iter 200] loss=4.5975 val_loss=0.0000 scale=1.0000 norm=0.5475\n",
      "[iter 300] loss=4.5662 val_loss=0.0000 scale=1.0000 norm=0.5597\n",
      "[iter 400] loss=4.5549 val_loss=0.0000 scale=2.0000 norm=1.1334\n",
      "[iter 0] loss=4.8487 val_loss=0.0000 scale=256.0000 norm=158.0449\n",
      "== Quitting at iteration / GRAD 0\n",
      "[iter 0] loss=4.8313 val_loss=0.0000 scale=1.0000 norm=0.6213\n",
      "[iter 100] loss=4.6947 val_loss=0.0000 scale=1.0000 norm=0.5642\n",
      "[iter 200] loss=4.6390 val_loss=0.0000 scale=2.0000 norm=1.1342\n",
      "[iter 300] loss=4.6116 val_loss=0.0000 scale=2.0000 norm=1.1451\n",
      "[iter 400] loss=4.5965 val_loss=0.0000 scale=1.0000 norm=0.5758\n",
      "[iter 0] loss=4.8551 val_loss=0.0000 scale=1.0000 norm=0.6246\n",
      "[iter 100] loss=4.6730 val_loss=0.0000 scale=1.0000 norm=0.5452\n",
      "[iter 200] loss=4.6034 val_loss=0.0000 scale=1.0000 norm=0.5446\n",
      "[iter 300] loss=4.5730 val_loss=0.0000 scale=1.0000 norm=0.5538\n",
      "[iter 400] loss=4.5574 val_loss=0.0000 scale=1.0000 norm=0.5608\n",
      "[iter 0] loss=4.8703 val_loss=0.0000 scale=1.0000 norm=0.6280\n",
      "[iter 100] loss=4.6688 val_loss=0.0000 scale=1.0000 norm=0.5425\n",
      "[iter 200] loss=4.5817 val_loss=0.0000 scale=2.0000 norm=1.0988\n",
      "[iter 300] loss=4.5565 val_loss=0.0000 scale=1.0000 norm=0.5619\n",
      "[iter 400] loss=4.5466 val_loss=0.0000 scale=1.0000 norm=0.5679\n",
      "[iter 0] loss=4.8676 val_loss=0.0000 scale=1.0000 norm=0.6267\n",
      "[iter 100] loss=4.6655 val_loss=0.0000 scale=1.0000 norm=0.5406\n",
      "[iter 200] loss=4.5803 val_loss=0.0000 scale=1.0000 norm=0.5465\n",
      "[iter 300] loss=4.5531 val_loss=0.0000 scale=1.0000 norm=0.5593\n",
      "[iter 400] loss=4.5430 val_loss=0.0000 scale=2.0000 norm=1.1300\n",
      "[iter 0] loss=4.8487 val_loss=0.0000 scale=256.0000 norm=158.0449\n",
      "== Quitting at iteration / GRAD 0\n",
      "[iter 0] loss=4.8520 val_loss=0.0000 scale=1.0000 norm=0.6260\n",
      "[iter 100] loss=4.7158 val_loss=0.0000 scale=1.0000 norm=0.5663\n",
      "[iter 200] loss=4.6586 val_loss=0.0000 scale=2.0000 norm=1.1332\n",
      "[iter 300] loss=4.6336 val_loss=0.0000 scale=2.0000 norm=1.1435\n",
      "[iter 400] loss=4.6197 val_loss=0.0000 scale=1.0000 norm=0.5746\n",
      "[iter 0] loss=4.8702 val_loss=0.0000 scale=1.0000 norm=0.6279\n",
      "[iter 100] loss=4.6878 val_loss=0.0000 scale=1.0000 norm=0.5474\n",
      "[iter 200] loss=4.6192 val_loss=0.0000 scale=1.0000 norm=0.5470\n",
      "[iter 300] loss=4.5892 val_loss=0.0000 scale=1.0000 norm=0.5562\n",
      "[iter 400] loss=4.5741 val_loss=0.0000 scale=1.0000 norm=0.5628\n",
      "[iter 0] loss=4.8807 val_loss=0.0000 scale=1.0000 norm=0.6302\n",
      "[iter 100] loss=4.6793 val_loss=0.0000 scale=1.0000 norm=0.5435\n",
      "[iter 200] loss=4.5995 val_loss=0.0000 scale=1.0000 norm=0.5487\n",
      "[iter 300] loss=4.5715 val_loss=0.0000 scale=2.0000 norm=1.1215\n",
      "[iter 400] loss=4.5604 val_loss=0.0000 scale=1.0000 norm=0.5678\n",
      "[iter 0] loss=4.8758 val_loss=0.0000 scale=1.0000 norm=0.6284\n",
      "[iter 100] loss=4.6740 val_loss=0.0000 scale=1.0000 norm=0.5415\n",
      "[iter 200] loss=4.5920 val_loss=0.0000 scale=1.0000 norm=0.5462\n",
      "[iter 300] loss=4.5625 val_loss=0.0000 scale=1.0000 norm=0.5597\n",
      "[iter 400] loss=4.5513 val_loss=0.0000 scale=1.0000 norm=0.5658\n",
      "[iter 0] loss=4.8487 val_loss=0.0000 scale=256.0000 norm=158.0449\n",
      "== Quitting at iteration / GRAD 0\n",
      "[iter 0] loss=4.8520 val_loss=0.0000 scale=1.0000 norm=0.6260\n",
      "[iter 100] loss=4.7158 val_loss=0.0000 scale=1.0000 norm=0.5663\n",
      "[iter 200] loss=4.6586 val_loss=0.0000 scale=2.0000 norm=1.1332\n",
      "[iter 300] loss=4.6336 val_loss=0.0000 scale=2.0000 norm=1.1435\n",
      "[iter 400] loss=4.6197 val_loss=0.0000 scale=1.0000 norm=0.5746\n",
      "[iter 0] loss=4.8571 val_loss=0.0000 scale=1.0000 norm=0.6268\n",
      "[iter 100] loss=4.6828 val_loss=0.0000 scale=1.0000 norm=0.5507\n",
      "[iter 200] loss=4.6116 val_loss=0.0000 scale=1.0000 norm=0.5496\n",
      "[iter 300] loss=4.5788 val_loss=0.0000 scale=2.0000 norm=1.1158\n",
      "[iter 400] loss=4.5643 val_loss=0.0000 scale=2.0000 norm=1.1288\n",
      "[iter 0] loss=4.8717 val_loss=0.0000 scale=1.0000 norm=0.6295\n",
      "[iter 100] loss=4.6748 val_loss=0.0000 scale=1.0000 norm=0.5453\n",
      "[iter 200] loss=4.5922 val_loss=0.0000 scale=1.0000 norm=0.5506\n",
      "[iter 300] loss=4.5634 val_loss=0.0000 scale=2.0000 norm=1.1268\n",
      "[iter 400] loss=4.5521 val_loss=0.0000 scale=1.0000 norm=0.5696\n",
      "[iter 0] loss=4.8687 val_loss=0.0000 scale=1.0000 norm=0.6278\n",
      "[iter 100] loss=4.6704 val_loss=0.0000 scale=1.0000 norm=0.5433\n",
      "[iter 200] loss=4.5780 val_loss=0.0000 scale=2.0000 norm=1.1001\n",
      "[iter 300] loss=4.5546 val_loss=0.0000 scale=1.0000 norm=0.5625\n",
      "[iter 400] loss=4.5457 val_loss=0.0000 scale=2.0000 norm=1.1330\n",
      "[iter 0] loss=4.8487 val_loss=0.0000 scale=256.0000 norm=158.0449\n",
      "== Quitting at iteration / GRAD 0\n",
      "[iter 0] loss=4.8520 val_loss=0.0000 scale=1.0000 norm=0.6260\n",
      "[iter 100] loss=4.7158 val_loss=0.0000 scale=1.0000 norm=0.5663\n",
      "[iter 200] loss=4.6586 val_loss=0.0000 scale=2.0000 norm=1.1332\n",
      "[iter 300] loss=4.6336 val_loss=0.0000 scale=2.0000 norm=1.1435\n",
      "[iter 400] loss=4.6197 val_loss=0.0000 scale=1.0000 norm=0.5746\n",
      "[iter 0] loss=4.8519 val_loss=0.0000 scale=1.0000 norm=0.6292\n",
      "[iter 100] loss=4.6737 val_loss=0.0000 scale=2.0000 norm=1.1071\n",
      "[iter 200] loss=4.6007 val_loss=0.0000 scale=1.0000 norm=0.5536\n",
      "[iter 300] loss=4.5703 val_loss=0.0000 scale=1.0000 norm=0.5635\n",
      "[iter 400] loss=4.5568 val_loss=0.0000 scale=1.0000 norm=0.5693\n",
      "[iter 0] loss=4.8680 val_loss=0.0000 scale=1.0000 norm=0.6312\n",
      "[iter 100] loss=4.6709 val_loss=0.0000 scale=1.0000 norm=0.5484\n",
      "[iter 200] loss=4.5896 val_loss=0.0000 scale=1.0000 norm=0.5536\n",
      "[iter 300] loss=4.5616 val_loss=0.0000 scale=1.0000 norm=0.5657\n",
      "[iter 400] loss=4.5516 val_loss=0.0000 scale=1.0000 norm=0.5724\n",
      "[iter 0] loss=4.8659 val_loss=0.0000 scale=1.0000 norm=0.6291\n",
      "[iter 100] loss=4.6670 val_loss=0.0000 scale=1.0000 norm=0.5453\n",
      "[iter 200] loss=4.5766 val_loss=0.0000 scale=1.0000 norm=0.5520\n",
      "[iter 300] loss=4.5524 val_loss=0.0000 scale=2.0000 norm=1.1295\n",
      "[iter 400] loss=4.5433 val_loss=0.0000 scale=1.0000 norm=0.5694\n",
      "[iter 0] loss=4.8487 val_loss=0.0000 scale=256.0000 norm=158.0449\n",
      "== Quitting at iteration / GRAD 0\n",
      "[iter 0] loss=4.8520 val_loss=0.0000 scale=1.0000 norm=0.6260\n",
      "[iter 100] loss=4.7158 val_loss=0.0000 scale=1.0000 norm=0.5663\n",
      "[iter 200] loss=4.6586 val_loss=0.0000 scale=2.0000 norm=1.1332\n",
      "[iter 300] loss=4.6336 val_loss=0.0000 scale=2.0000 norm=1.1435\n",
      "[iter 400] loss=4.6197 val_loss=0.0000 scale=1.0000 norm=0.5746\n",
      "[iter 0] loss=4.8519 val_loss=0.0000 scale=1.0000 norm=0.6292\n",
      "[iter 100] loss=4.6737 val_loss=0.0000 scale=2.0000 norm=1.1071\n",
      "[iter 200] loss=4.6007 val_loss=0.0000 scale=1.0000 norm=0.5536\n",
      "[iter 300] loss=4.5703 val_loss=0.0000 scale=1.0000 norm=0.5635\n",
      "[iter 400] loss=4.5568 val_loss=0.0000 scale=1.0000 norm=0.5693\n",
      "[iter 0] loss=4.8725 val_loss=0.0000 scale=1.0000 norm=0.6303\n",
      "[iter 100] loss=4.6697 val_loss=0.0000 scale=1.0000 norm=0.5433\n",
      "[iter 200] loss=4.5880 val_loss=0.0000 scale=1.0000 norm=0.5482\n",
      "[iter 300] loss=4.5594 val_loss=0.0000 scale=2.0000 norm=1.1244\n",
      "[iter 400] loss=4.5490 val_loss=0.0000 scale=1.0000 norm=0.5691\n",
      "[iter 0] loss=4.8693 val_loss=0.0000 scale=1.0000 norm=0.6284\n",
      "[iter 100] loss=4.6671 val_loss=0.0000 scale=1.0000 norm=0.5420\n",
      "[iter 200] loss=4.5791 val_loss=0.0000 scale=1.0000 norm=0.5479\n",
      "[iter 300] loss=4.5530 val_loss=0.0000 scale=2.0000 norm=1.1217\n",
      "[iter 400] loss=4.5430 val_loss=0.0000 scale=1.0000 norm=0.5662\n",
      "[iter 0] loss=4.8487 val_loss=0.0000 scale=256.0000 norm=158.0449\n",
      "== Quitting at iteration / GRAD 0\n",
      "[iter 0] loss=4.8520 val_loss=0.0000 scale=1.0000 norm=0.6260\n",
      "[iter 100] loss=4.7158 val_loss=0.0000 scale=1.0000 norm=0.5663\n",
      "[iter 200] loss=4.6586 val_loss=0.0000 scale=2.0000 norm=1.1332\n",
      "[iter 300] loss=4.6336 val_loss=0.0000 scale=2.0000 norm=1.1435\n",
      "[iter 400] loss=4.6197 val_loss=0.0000 scale=1.0000 norm=0.5746\n",
      "[iter 0] loss=4.8519 val_loss=0.0000 scale=1.0000 norm=0.6292\n",
      "[iter 100] loss=4.6737 val_loss=0.0000 scale=2.0000 norm=1.1071\n",
      "[iter 200] loss=4.6007 val_loss=0.0000 scale=1.0000 norm=0.5536\n",
      "[iter 300] loss=4.5703 val_loss=0.0000 scale=1.0000 norm=0.5635\n",
      "[iter 400] loss=4.5568 val_loss=0.0000 scale=1.0000 norm=0.5693\n",
      "[iter 0] loss=4.8643 val_loss=0.0000 scale=1.0000 norm=0.6286\n",
      "[iter 100] loss=4.6657 val_loss=0.0000 scale=1.0000 norm=0.5440\n",
      "[iter 200] loss=4.5908 val_loss=0.0000 scale=1.0000 norm=0.5479\n",
      "[iter 300] loss=4.5598 val_loss=0.0000 scale=1.0000 norm=0.5613\n",
      "[iter 400] loss=4.5488 val_loss=0.0000 scale=2.0000 norm=1.1365\n",
      "[iter 0] loss=4.8630 val_loss=0.0000 scale=1.0000 norm=0.6269\n",
      "[iter 100] loss=4.6619 val_loss=0.0000 scale=1.0000 norm=0.5415\n",
      "[iter 200] loss=4.5800 val_loss=0.0000 scale=1.0000 norm=0.5473\n",
      "[iter 300] loss=4.5527 val_loss=0.0000 scale=1.0000 norm=0.5603\n",
      "[iter 400] loss=4.5427 val_loss=0.0000 scale=1.0000 norm=0.5664\n",
      "[iter 0] loss=4.8487 val_loss=0.0000 scale=256.0000 norm=158.0449\n",
      "== Quitting at iteration / GRAD 0\n",
      "[iter 0] loss=4.8520 val_loss=0.0000 scale=1.0000 norm=0.6260\n",
      "[iter 100] loss=4.7158 val_loss=0.0000 scale=1.0000 norm=0.5663\n",
      "[iter 200] loss=4.6586 val_loss=0.0000 scale=2.0000 norm=1.1332\n",
      "[iter 300] loss=4.6336 val_loss=0.0000 scale=2.0000 norm=1.1435\n",
      "[iter 400] loss=4.6197 val_loss=0.0000 scale=1.0000 norm=0.5746\n",
      "[iter 0] loss=4.8519 val_loss=0.0000 scale=1.0000 norm=0.6292\n",
      "[iter 100] loss=4.6737 val_loss=0.0000 scale=2.0000 norm=1.1071\n",
      "[iter 200] loss=4.6007 val_loss=0.0000 scale=1.0000 norm=0.5536\n",
      "[iter 300] loss=4.5703 val_loss=0.0000 scale=1.0000 norm=0.5635\n",
      "[iter 400] loss=4.5568 val_loss=0.0000 scale=1.0000 norm=0.5693\n",
      "[iter 0] loss=4.8643 val_loss=0.0000 scale=1.0000 norm=0.6286\n",
      "[iter 100] loss=4.6657 val_loss=0.0000 scale=1.0000 norm=0.5440\n",
      "[iter 200] loss=4.5908 val_loss=0.0000 scale=1.0000 norm=0.5479\n",
      "[iter 300] loss=4.5598 val_loss=0.0000 scale=1.0000 norm=0.5613\n",
      "[iter 400] loss=4.5488 val_loss=0.0000 scale=2.0000 norm=1.1365\n",
      "[iter 0] loss=4.8729 val_loss=0.0000 scale=1.0000 norm=0.6300\n",
      "[iter 100] loss=4.6731 val_loss=0.0000 scale=1.0000 norm=0.5448\n",
      "[iter 200] loss=4.5912 val_loss=0.0000 scale=1.0000 norm=0.5491\n",
      "[iter 300] loss=4.5603 val_loss=0.0000 scale=1.0000 norm=0.5629\n",
      "[iter 400] loss=4.5500 val_loss=0.0000 scale=1.0000 norm=0.5687\n",
      "[iter 0] loss=4.8487 val_loss=0.0000 scale=256.0000 norm=158.0449\n",
      "== Quitting at iteration / GRAD 0\n",
      "[iter 0] loss=4.8520 val_loss=0.0000 scale=1.0000 norm=0.6260\n",
      "[iter 100] loss=4.7158 val_loss=0.0000 scale=1.0000 norm=0.5663\n",
      "[iter 200] loss=4.6586 val_loss=0.0000 scale=2.0000 norm=1.1332\n",
      "[iter 300] loss=4.6336 val_loss=0.0000 scale=2.0000 norm=1.1435\n",
      "[iter 400] loss=4.6197 val_loss=0.0000 scale=1.0000 norm=0.5746\n",
      "[iter 0] loss=4.8519 val_loss=0.0000 scale=1.0000 norm=0.6292\n",
      "[iter 100] loss=4.6737 val_loss=0.0000 scale=2.0000 norm=1.1071\n",
      "[iter 200] loss=4.6007 val_loss=0.0000 scale=1.0000 norm=0.5536\n",
      "[iter 300] loss=4.5703 val_loss=0.0000 scale=1.0000 norm=0.5635\n",
      "[iter 400] loss=4.5568 val_loss=0.0000 scale=1.0000 norm=0.5693\n",
      "[iter 0] loss=4.8643 val_loss=0.0000 scale=1.0000 norm=0.6286\n",
      "[iter 100] loss=4.6657 val_loss=0.0000 scale=1.0000 norm=0.5440\n",
      "[iter 200] loss=4.5908 val_loss=0.0000 scale=1.0000 norm=0.5479\n",
      "[iter 300] loss=4.5598 val_loss=0.0000 scale=1.0000 norm=0.5613\n",
      "[iter 400] loss=4.5488 val_loss=0.0000 scale=2.0000 norm=1.1365\n",
      "[iter 0] loss=4.8700 val_loss=0.0000 scale=1.0000 norm=0.6287\n",
      "[iter 100] loss=4.6660 val_loss=0.0000 scale=1.0000 norm=0.5418\n",
      "[iter 200] loss=4.5834 val_loss=0.0000 scale=1.0000 norm=0.5462\n",
      "[iter 300] loss=4.5540 val_loss=0.0000 scale=2.0000 norm=1.1190\n",
      "[iter 400] loss=4.5436 val_loss=0.0000 scale=1.0000 norm=0.5659\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curve(model_nb, X_train, y_train, 10, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Learning Cruve, It seems that validation error and Training error did not reache the minimum error yet, which means more data would be useful in this case. Furthermore, maybe more features help to improve performance as well.\n",
    "If this model was going to be put into production, We would have to wait to get more data in order to start the retraining system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just saving name of features after transformers\n",
    "one_hot_names = model_nb.steps[0][1].transformers_[0][1][1].get_feature_names_out().tolist()\n",
    "median_names = model_nb.steps[0][1].transformers_[1][1][0].feature_names_in_.tolist()\n",
    "zero_names = model_nb.steps[0][1].transformers_[2][1][0].feature_names_in_.tolist()\n",
    "columns_after_transformation = one_hot_names+median_names+zero_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_permutation_importance(model_nb, X=X_train, y=y_train, columns=all_columns, n_repeats=5, scoring='neg_mean_squared_error', n_best=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above We can see the ranking of best features. Top 3 are: `n_distinct_items`, `on_demand` and `found_rate`. But `n_distinct_items` is the most important with clearence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Test and Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1) Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering test set\n",
    "df_orders_test = pipe_feature_engineering.transform(df_orders_test)\n",
    "# Selecting only used features\n",
    "X_test = df_orders_test[all_columns]\n",
    "# Y of test set\n",
    "y_test = df_orders_test['total_minutes']\n",
    "# Getting predictions\n",
    "y_predictions_test = model_nb.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Percentage Error in Test Set is: 25.43396628883649%\n"
     ]
    }
   ],
   "source": [
    "# performance in test set\n",
    "print(f'Mean Absolute Percentage Error in Test Set is: {100*mean_absolute_percentage_error(y_predictions_test,y_test)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the model is not overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2) Submission Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering submission\n",
    "df_submission = pipe_feature_engineering.transform(df_submission)\n",
    "# Selecting only used features\n",
    "X_submission = df_submission[all_columns]\n",
    "# getting point estimates for total_miutes\n",
    "y_predictions_submission = model_nb.predict(X_submission)\n",
    "# Data frame with order_id and estimates\n",
    "df_submission_predictions = pd.DataFrame({'order_id':df_submission['order_id'], 'total_minutes':y_predictions_submission})\n",
    "# Getting confidence interval for total_minutes (95%)\n",
    "df_predictions_with_interval = get_intervals(model=model_nb, X=X_submission, confidence=0.95)\n",
    "# lower bound\n",
    "df_submission_predictions['total_minutes_lower_bound'] = df_predictions_with_interval['interval'].apply(lambda x: x[0])\n",
    "# upper bound\n",
    "df_submission_predictions['total_minutes_upper_bound'] = df_predictions_with_interval['interval'].apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission_predictions.to_csv(os.path.join(DATA_INPUT_PATH, 'submission_predictions_notebook.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s</th>\n",
       "      <th>scale</th>\n",
       "      <th>interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.323648</td>\n",
       "      <td>63.177627</td>\n",
       "      <td>(33.50219647059474, 119.13883206605864)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          s      scale                                 interval\n",
       "0  0.323648  63.177627  (33.50219647059474, 119.13883206605864)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_intervals(model=model_nb, X=X_submission, confidence=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>total_minutes</th>\n",
       "      <th>total_minutes_lower_bound</th>\n",
       "      <th>total_minutes_upper_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3a226ea48debc0a7ae9950d5540f2f34</td>\n",
       "      <td>66.574684</td>\n",
       "      <td>33.502196</td>\n",
       "      <td>119.138832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9bf29b56619fcaf60b52690a848e10bb</td>\n",
       "      <td>66.303182</td>\n",
       "      <td>31.130062</td>\n",
       "      <td>124.600759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>299d948a5fd2cf2a921894b9bd24b94e</td>\n",
       "      <td>103.305217</td>\n",
       "      <td>63.017244</td>\n",
       "      <td>160.041732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150bd9290b2125e67541098173e2cfb1</td>\n",
       "      <td>112.680583</td>\n",
       "      <td>67.578341</td>\n",
       "      <td>176.896466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>844f746ff505c01c088de90bce067b94</td>\n",
       "      <td>46.454359</td>\n",
       "      <td>20.962278</td>\n",
       "      <td>89.715678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>6cbabd6e0ed6bb1e12d25d59d5c8cd07</td>\n",
       "      <td>117.297853</td>\n",
       "      <td>67.541459</td>\n",
       "      <td>190.008226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>288dd3cb1cec0f1f5b4c3d336df1f3d4</td>\n",
       "      <td>73.983217</td>\n",
       "      <td>39.591351</td>\n",
       "      <td>126.610600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1bfc0429832b9dab41d2a63eb8d9a076</td>\n",
       "      <td>56.903023</td>\n",
       "      <td>25.230379</td>\n",
       "      <td>111.212573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>b8a1cc826cc9a7190a79e45d41a0a7e2</td>\n",
       "      <td>71.639003</td>\n",
       "      <td>33.340819</td>\n",
       "      <td>135.450769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>f1d910271fe4182d87bdea049b7749c4</td>\n",
       "      <td>51.588769</td>\n",
       "      <td>24.819851</td>\n",
       "      <td>95.311069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              order_id  total_minutes  \\\n",
       "0     3a226ea48debc0a7ae9950d5540f2f34      66.574684   \n",
       "1     9bf29b56619fcaf60b52690a848e10bb      66.303182   \n",
       "2     299d948a5fd2cf2a921894b9bd24b94e     103.305217   \n",
       "3     150bd9290b2125e67541098173e2cfb1     112.680583   \n",
       "4     844f746ff505c01c088de90bce067b94      46.454359   \n",
       "...                                ...            ...   \n",
       "1995  6cbabd6e0ed6bb1e12d25d59d5c8cd07     117.297853   \n",
       "1996  288dd3cb1cec0f1f5b4c3d336df1f3d4      73.983217   \n",
       "1997  1bfc0429832b9dab41d2a63eb8d9a076      56.903023   \n",
       "1998  b8a1cc826cc9a7190a79e45d41a0a7e2      71.639003   \n",
       "1999  f1d910271fe4182d87bdea049b7749c4      51.588769   \n",
       "\n",
       "      total_minutes_lower_bound  total_minutes_upper_bound  \n",
       "0                     33.502196                 119.138832  \n",
       "1                     31.130062                 124.600759  \n",
       "2                     63.017244                 160.041732  \n",
       "3                     67.578341                 176.896466  \n",
       "4                     20.962278                  89.715678  \n",
       "...                         ...                        ...  \n",
       "1995                  67.541459                 190.008226  \n",
       "1996                  39.591351                 126.610600  \n",
       "1997                  25.230379                 111.212573  \n",
       "1998                  33.340819                 135.450769  \n",
       "1999                  24.819851                  95.311069  \n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of output\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.histplot(df_orders_train['total_minutes'], kde=True)\n",
    "plt.axvline(df_submission_predictions.total_minutes.mean(), color='k', ls='--', linestyle='dashed',\n",
    "            label=f'Average Total Minutes: {np.round(df_submission_predictions.total_minutes.mean(),2)}')\n",
    "plt.xlabel(\"Total Minutes\")\n",
    "plt.title('Distribution of Total Minutes',fontsize=15)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is very similar to the distribution of training and testing sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Exporting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model \n",
    "filename_model = 'model.sav'\n",
    "pickle.dump(model_nb, open(os.path.join(MODEL_PATH, filename_model), 'wb'))\n",
    "# feature engineering pipe\n",
    "filename_feature_engineering_pipe = 'feature_engineering_pipe.sav'\n",
    "pickle.dump(pipe_feature_engineering, open(os.path.join(MODEL_PATH, filename_feature_engineering_pipe), 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps/ Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data: Despite We had a good MAPE in our models, It's very posible to improve this performance by adding more samples and features, as We can see in the learning curve pattern. Also, It would be really useful to acquire data from the other days of the week and different months as well. When It comes to which features to add, I would say:\n",
    "    - Weather conditions (real time)\n",
    "    - Traffic conditions (real time)\n",
    "    - Vehicle (bike, car, motorcycle)\n",
    "- Models: The modeling step can be improved a lot. We could think more about feature engineering, for example.\n",
    "- Monitoring: The application if Put into production enviroment, should be able to produce responses in real time. As the scenario evolves, It would be important to create some dashboards and alarms in case of weird predictions and anomalies, as well as to monitor the performance, concept and data drif.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a6f7b07b20f4cf172f035b867796e18e995318450c83b6d17ec9b748e82eefe6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('case_cornershop_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
